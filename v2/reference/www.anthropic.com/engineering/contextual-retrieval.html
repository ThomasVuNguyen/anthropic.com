<!DOCTYPE html><html lang="en" class="anthropicsans_eac0b31f-module__tjnuGq__variable anthropicserif_87b6fa7d-module__quIBbW__variable anthropicmono_fae19af3-module__c5XAsG__variable copernicus_4da799c5-module__dijTSq__variable styrenea_f8492ab1-module__HimLXW__variable styreneb_278af5c6-module__wkOAdG__variable tiempostext_4eff4b4c-module__mpviCW__variable jetbrainsmono_7d7bdbc6-module__j_XgJq__variable"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/chunks/ec368b341879b233.css" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/38fee8473f816a4a.css" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/caf680e685668b99.css" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/ad266d0a6bc656af.css" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/e2c670ea67fc2bbb.css" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/758311c654d998de.css" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz" href="/_next/static/chunks/f4386f5ba7642880.js"/><script src="/_next/static/chunks/573c649abe04b34a.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/d0300bffb79131f2.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/08dcfc3b15383cd6.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/turbopack-07052ba808d12dd9.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/d96012bcfc98706a.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/d80b3790a119a285.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/1fb574e7be3f9a05.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/9a604444e87766dd.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/c1896c986be1a2e2.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/f5a33d7993e253c8.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/496bc8a289f448d1.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/b1040bb2d2fbd1e5.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/2e3229a62c65aaec.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/5c1988096a7b174a.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/f563a58c137d4bc2.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/2fd2aa01a4bc9178.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/630870b77208f43d.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/010986693eb1c9c2.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/dabacb64939959b3.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/c0d75d4ca01ae43d.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/6c680011ff6c5ba2.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/81716bb24f5a6f8f.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/7c80d08c36d49463.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/33647e5ba6496195.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/667473da0b5c11bc.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><script src="/_next/static/chunks/2c9eb3077aa18f16.js" async="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script><link rel="preload" href="/_next/static/chunks/7e4146583225b449.css" as="style" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"/><meta name="next-size-adjust" content=""/><meta name="theme-color" content="#141413"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule="" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz"></script></head><body><div hidden=""><!--$?--><template id="B:0"></template><!--/$--></div><header class="SiteHeader-module-scss-module__zKj4Ca__header" data-theme="light"><div class="SiteHeader-module-scss-module__zKj4Ca__skipLinks"><a href="#main-content" class="SiteHeader-module-scss-module__zKj4Ca__skipLink">Skip to main content</a><a href="#footer" class="SiteHeader-module-scss-module__zKj4Ca__skipLink">Skip to footer</a></div><div class="page-wrapper SiteHeader-module-scss-module__zKj4Ca__root"><a href="/" aria-label="Home"><div class="SiteHeader-module-scss-module__zKj4Ca__logoDesktop"><div class="LogoWordmark-module-scss-module__Sdgt-q__logo-wrapper"><svg class="LogoWordmark-module-scss-module__Sdgt-q__logo-static" width="570" height="64" viewBox="0 0 570 64" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Anthropic"><path d="M139.492 12.9945H160.265V62.9392H173.525V12.9945H194.298V1.06077H139.492V12.9945Z" fill="currentColor"></path><path d="M116.066 44.3757L88.221 1.06077H73.1934V62.9392H86.011V19.6243L113.856 62.9392H128.884V1.06077H116.066V44.3757Z" fill="currentColor"></path><path d="M247.337 25.7238H218.166V1.06077H204.906V62.9392H218.166V37.6575H247.337V62.9392H260.597V1.06077H247.337V25.7238Z" fill="currentColor"></path><path d="M24.663 1.06077L0 62.9392H13.7901L18.834 49.9447H44.6365L49.6796 62.9392H63.4696L38.8066 1.06077H24.663ZM23.2946 38.453L31.7348 16.7072L40.175 38.453H23.2946Z" fill="currentColor"></path><path d="M370.475 0C352.619 0 339.978 13.2597 339.978 32.0884C339.978 50.7403 352.619 64 370.475 64C388.243 64 400.796 50.7403 400.796 32.0884C400.796 13.2597 388.243 0 370.475 0ZM370.475 51.6243C360.044 51.6243 353.68 44.1989 353.68 32.0884C353.68 19.8011 360.044 12.3757 370.475 12.3757C380.818 12.3757 387.094 19.8011 387.094 32.0884C387.094 44.1989 380.818 51.6243 370.475 51.6243Z" fill="currentColor"></path><path d="M555.845 42.1657C553.547 48.1768 548.95 51.6243 542.674 51.6243C532.243 51.6243 525.878 44.1989 525.878 32.0884C525.878 19.8011 532.243 12.3757 542.674 12.3757C548.95 12.3757 553.547 15.8232 555.845 21.8343H569.901C566.453 8.57459 556.11 0 542.674 0C524.818 0 512.177 13.2597 512.177 32.0884C512.177 50.7403 524.818 64 542.674 64C556.199 64 566.541 55.337 569.989 42.1657H555.845Z" fill="currentColor"></path><path d="M471.337 1.06077L496 62.9392H509.525L484.862 1.06077H471.337Z" fill="currentColor"></path><path d="M443.403 1.06077H413.171V62.9392H426.431V40.4862H443.403C457.459 40.4862 466.033 33.0608 466.033 20.7735C466.033 8.48619 457.459 1.06077 443.403 1.06077ZM442.784 28.5525H426.431V12.9945H442.784C449.326 12.9945 452.773 15.6464 452.773 20.7735C452.773 25.9006 449.326 28.5525 442.784 28.5525Z" fill="currentColor"></path><path d="M329.812 19.8895C329.812 8.22099 321.238 1.06077 307.182 1.06077H276.95V62.9392H290.21V38.7182H304.971L318.232 62.9392H332.906L318.223 36.8734C325.593 34.0402 329.812 28.0743 329.812 19.8895ZM290.21 12.9945H306.564C313.105 12.9945 316.552 15.3812 316.552 19.8895C316.552 24.3978 313.105 26.7845 306.564 26.7845H290.21V12.9945Z" fill="currentColor"></path></svg><div class="LogoWordmark-module-scss-module__Sdgt-q__logo-lottie"></div></div></div><svg class="Icon-module-scss-module__lqbdHG__icon SiteHeader-module-scss-module__zKj4Ca__logoMobile" width="32" height="32" viewBox="0 0 46 32"><path d="M32.73 0h-6.945L38.45 32h6.945L32.73 0ZM12.665 0 0 32h7.082l2.59-6.72h13.25l2.59 6.72h7.082L19.929 0h-7.264Zm-.702 19.337 4.334-11.246 4.334 11.246h-8.668Z" fill="currentColor"></path></svg></a><div class="SiteHeader-module-scss-module__zKj4Ca__contentWrapper"><nav class="SiteHeader-module-scss-module__zKj4Ca__nav"><ul class="SiteHeader-module-scss-module__zKj4Ca__navList"><li class="body-3 SiteHeader-module-scss-module__zKj4Ca__navItem"><a href="/research" class="SiteHeader-module-scss-module__zKj4Ca__navText">Research</a></li><li class="body-3 SiteHeader-module-scss-module__zKj4Ca__navItem"><a href="/economic-futures" class="SiteHeader-module-scss-module__zKj4Ca__navText">Economic Futures</a></li><li class="body-3 SiteHeader-module-scss-module__zKj4Ca__navItem" data-category="Commitments"><button class="SiteHeader-module-scss-module__zKj4Ca__navText" aria-haspopup="menu" aria-expanded="false" aria-controls="nav-dropdown-Commitments"><span>Commitments</span><svg class="Icon-module-scss-module__lqbdHG__icon SiteHeader-module-scss-module__zKj4Ca__caretIcon" width="12" height="6.13" viewBox="0 0 8 5"><path d="M7.3016 0.231808C7.44932 0.0678162 7.70306 0.0546398 7.86724 0.20212C8.03137 0.349888 8.04461 0.603568 7.89692 0.767766L4.29684 4.76791L4.23434 4.82417C4.16662 4.87328 4.08425 4.89995 3.99918 4.89995C3.88588 4.89989 3.77733 4.85213 3.70152 4.76791L0.10144 0.767766L0.0537825 0.702139C-0.040206 0.541753 -0.0124254 0.331356 0.131128 0.20212C0.274775 0.0728844 0.486972 0.0674593 0.636608 0.1779L0.696765 0.231808L3.99918 3.90148L7.3016 0.231808Z" fill="currentColor"></path></svg></button></li><li class="body-3 SiteHeader-module-scss-module__zKj4Ca__navItem" data-category="Learn"><button class="SiteHeader-module-scss-module__zKj4Ca__navText" aria-haspopup="menu" aria-expanded="false" aria-controls="nav-dropdown-Learn"><span>Learn</span><svg class="Icon-module-scss-module__lqbdHG__icon SiteHeader-module-scss-module__zKj4Ca__caretIcon" width="12" height="6.13" viewBox="0 0 8 5"><path d="M7.3016 0.231808C7.44932 0.0678162 7.70306 0.0546398 7.86724 0.20212C8.03137 0.349888 8.04461 0.603568 7.89692 0.767766L4.29684 4.76791L4.23434 4.82417C4.16662 4.87328 4.08425 4.89995 3.99918 4.89995C3.88588 4.89989 3.77733 4.85213 3.70152 4.76791L0.10144 0.767766L0.0537825 0.702139C-0.040206 0.541753 -0.0124254 0.331356 0.131128 0.20212C0.274775 0.0728844 0.486972 0.0674593 0.636608 0.1779L0.696765 0.231808L3.99918 3.90148L7.3016 0.231808Z" fill="currentColor"></path></svg></button></li><li class="body-3 SiteHeader-module-scss-module__zKj4Ca__navItem"><a href="/news" class="SiteHeader-module-scss-module__zKj4Ca__navText">News</a></li></ul></nav><div class="SiteHeader-module-scss-module__zKj4Ca__claudeCtaWrapper"><a href="https://claude.ai/" class="SiteHeader-module-scss-module__zKj4Ca__claudeCtaButton body-3" target="_blank" rel="noopener noreferrer">Try Claude</a><div class="SiteHeader-module-scss-module__zKj4Ca__claudeCtaDropdownTrigger"><svg class="Icon-module-scss-module__lqbdHG__icon SiteHeader-module-scss-module__zKj4Ca__claudeCtaIcon" width="12" height="6.13" viewBox="0 0 8 5"><path d="M7.3016 0.231808C7.44932 0.0678162 7.70306 0.0546398 7.86724 0.20212C8.03137 0.349888 8.04461 0.603568 7.89692 0.767766L4.29684 4.76791L4.23434 4.82417C4.16662 4.87328 4.08425 4.89995 3.99918 4.89995C3.88588 4.89989 3.77733 4.85213 3.70152 4.76791L0.10144 0.767766L0.0537825 0.702139C-0.040206 0.541753 -0.0124254 0.331356 0.131128 0.20212C0.274775 0.0728844 0.486972 0.0674593 0.636608 0.1779L0.696765 0.231808L3.99918 3.90148L7.3016 0.231808Z" fill="currentColor"></path></svg></div></div><button class="SiteHeader-module-scss-module__zKj4Ca__mobileIcon" aria-label="Navigation menu"><svg class="Icon-module-scss-module__lqbdHG__icon" width="24" height="24" viewBox="0 0 40 40"><path d="M18.75 28C19.1641 28.0002 19.5 28.3359 19.5 28.75C19.4999 29.1641 19.164 29.4998 18.75 29.5H7.91699C7.50281 29.5 7.16705 29.1642 7.16699 28.75C7.16699 28.3358 7.50278 28 7.91699 28H18.75ZM32.084 19.25C32.4979 19.2504 32.834 19.586 32.834 20C32.8339 20.4139 32.4979 20.7496 32.084 20.75H7.91699C7.50281 20.75 7.16705 20.4142 7.16699 20C7.16699 19.5858 7.50278 19.25 7.91699 19.25H32.084ZM32.084 10.5C32.4979 10.5004 32.834 10.836 32.834 11.25C32.8339 11.6639 32.4979 11.9996 32.084 12H7.91699C7.50282 12 7.16706 11.6642 7.16699 11.25C7.16699 10.8358 7.50278 10.5 7.91699 10.5H32.084Z" fill="currentColor"></path></svg></button></div></div></header><main id="main-content" class=""><section class="page-wrapper HeroEngineering-module-scss-module__j1ivRa__hero" aria-label="Engineering Article Hero"><a class="body-2 bold HeroEngineering-module-scss-module__j1ivRa__hubLink" href="/engineering">Engineering at Anthropic</a><div class="HeroEngineering-module-scss-module__j1ivRa__content"><div class="HeroEngineering-module-scss-module__j1ivRa__header"><div class="HeroEngineering-module-scss-module__j1ivRa__heroImage"><img alt="" loading="lazy" width="2554" height="2554" decoding="async" data-nimg="1" style="color:transparent" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/7e2e39544a35760367049072406377a54f2b58c0-2554x2554.svg"/></div><h1 class="headline-1">Introducing Contextual Retrieval</h1></div><div class="HeroEngineering-module-scss-module__j1ivRa__metadata"><p class="body-2 HeroEngineering-module-scss-module__j1ivRa__date">Published <!-- -->Sep 19, 2024</p><p class="body-large-1 HeroEngineering-module-scss-module__j1ivRa__summary">For an AI model to be useful in specific contexts, it often needs access to background knowledge. </p></div></div></section><div class="page-wrapper"><article><div class=""><div class="Body-module-scss-module__z40yvW__body" data-theme="ivory"><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">For an AI model to be useful in specific contexts, it often needs access to background knowledge. For example, customer support chatbots need knowledge about the specific business they&#x27;re being used for, and legal analyst bots need to know about a vast array of past cases.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Developers typically enhance an AI model&#x27;s knowledge using Retrieval-Augmented Generation (RAG). RAG is a method that retrieves relevant information from a knowledge base and appends it to the user&#x27;s prompt, significantly enhancing the model&#x27;s response. The problem is that traditional RAG solutions remove context when encoding information, which often results in the system failing to retrieve the relevant information from the knowledge base.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">In this post, we outline a method that dramatically improves the retrieval step in RAG. The method is called “Contextual Retrieval” and uses two sub-techniques: Contextual Embeddings and Contextual BM25. This method can reduce the number of failed retrievals by 49% and, when combined with reranking, by 67%. These represent significant improvements in retrieval accuracy, which directly translates to better performance in downstream tasks. </p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">You can easily deploy your own Contextual Retrieval solution with Claude with <a href="https://platform.claude.com/cookbook/capabilities-contextual-embeddings-guide" target="_blank" rel="noopener noreferrer">our cookbook</a>.</p><h3 class="Body-module-scss-module__z40yvW__reading-column headline-5 post-section" id="a-note-on-simply-using-a-longer-prompt">A note on simply using a longer prompt</h3><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Sometimes the simplest solution is the best. If your knowledge base is smaller than 200,000 tokens (about 500 pages of material), you can just include the entire knowledge base in the prompt that you give the model, with no need for RAG or similar methods.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">A few weeks ago, we released <a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching">prompt caching</a> for Claude, which makes this approach significantly faster and more cost-effective. Developers can now cache frequently used prompts between API calls, reducing latency by &gt; 2x and costs by up to 90% (you can see how it works by reading our <a href="https://platform.claude.com/cookbook/misc-prompt-caching" target="_blank" rel="noopener noreferrer">prompt caching cookbook</a>).</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">However, as your knowledge base grows, you&#x27;ll need a more scalable solution. That’s where Contextual Retrieval comes in.</p><h2 class="Body-module-scss-module__z40yvW__reading-column headline-4 post-heading" id="a-primer-on-rag-scaling-to-larger-knowledge-bases">A primer on RAG: scaling to larger knowledge bases</h2><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">For larger knowledge bases that don&#x27;t fit within the context window, RAG is the typical solution. RAG works by preprocessing a knowledge base using the following steps:</p><ol class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text"><li>Break down the knowledge base (the “corpus” of documents) into smaller chunks of text, usually no more than a few hundred tokens;</li><li>Use an embedding model to convert these chunks into vector embeddings that encode meaning;</li><li>Store these embeddings in a vector database that allows for searching by semantic similarity.</li></ol><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">At runtime, when a user inputs a query to the model, the vector database is used to find the most relevant chunks based on semantic similarity to the query. Then, the most relevant chunks are added to the prompt sent to the generative model.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">While embedding models excel at capturing semantic relationships, they can miss crucial exact matches. Fortunately, there’s an older technique that can assist in these situations. BM25 (Best Matching 25) is a ranking function that uses lexical matching to find precise word or phrase matches. It&#x27;s particularly effective for queries that include unique identifiers or technical terms.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">BM25 works by building upon the TF-IDF (Term Frequency-Inverse Document Frequency) concept. TF-IDF measures how important a word is to a document in a collection. BM25 refines this by considering document length and applying a saturation function to term frequency, which helps prevent common words from dominating the results.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Here’s how BM25 can succeed where semantic embeddings fail: Suppose a user queries &quot;Error code TS-999&quot; in a technical support database. An embedding model might find content about error codes in general, but could miss the exact &quot;TS-999&quot; match. BM25 looks for this specific text string to identify the relevant documentation.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">RAG solutions can more accurately retrieve the most applicable chunks by combining the embeddings and BM25 techniques using the following steps:</p><ol class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text"><li>Break down the knowledge base (the &quot;corpus&quot; of documents) into smaller chunks of text, usually no more than a few hundred tokens;</li><li>Create TF-IDF encodings and semantic embeddings for these chunks;</li><li>Use BM25 to find top chunks based on exact matches;</li><li>Use embeddings to find top chunks based on semantic similarity;</li><li>Combine and deduplicate results from (3) and (4) using rank fusion techniques;</li><li>Add the top-K chunks to the prompt to generate the response.</li></ol><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">By leveraging both BM25 and embedding models, traditional RAG systems can provide more comprehensive and accurate results, balancing precise term matching with broader semantic understanding.</p><div class="Body-module-scss-module__z40yvW__media-column Body-module-scss-module__z40yvW__inline"><figure class="ImageWithCaption-module-scss-module__Duq99q__e-imageWithCaption"><img loading="lazy" width="3840" height="2160" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F45603646e979c62349ce27744a940abf30200d57-3840x2160.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F45603646e979c62349ce27744a940abf30200d57-3840x2160.png&amp;w=3840&amp;q=75"/><figcaption class="caption">A Standard Retrieval-Augmented Generation (RAG) system that uses both embeddings and Best Match 25 (BM25) to retrieve information. TF-IDF (term frequency-inverse document frequency) measures word importance and forms the basis for BM25.</figcaption></figure></div><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">This approach allows you to cost-effectively scale to enormous knowledge bases, far beyond what could fit in a single prompt. But these traditional RAG systems have a significant limitation: they often destroy context.</p><h3 class="Body-module-scss-module__z40yvW__reading-column headline-5 post-section" id="the-context-conundrum-in-traditional-rag">The context conundrum in traditional RAG</h3><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">In traditional RAG, documents are typically split into smaller chunks for efficient retrieval. While this approach works well for many applications, it can lead to problems when individual chunks lack sufficient context.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">For example, imagine you had a collection of financial information (say, U.S. SEC filings) embedded in your knowledge base, and you received the following question: <em>&quot;What was the revenue growth for ACME Corp in Q2 2023?&quot;</em></p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">A relevant chunk might contain the text: <em>&quot;The company&#x27;s revenue grew by 3% over the previous quarter.&quot;</em> However, this chunk on its own doesn&#x27;t specify which company it&#x27;s referring to or the relevant time period, making it difficult to retrieve the right information or use the information effectively.</p><h2 class="Body-module-scss-module__z40yvW__reading-column headline-4 post-heading" id="introducing-contextual-retrieval">Introducing Contextual Retrieval</h2><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Contextual Retrieval solves this problem by prepending chunk-specific explanatory context to each chunk before embedding (“Contextual Embeddings”) and creating the BM25 index (“Contextual BM25”).</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Let’s return to our SEC filings collection example. Here&#x27;s an example of how a chunk might be transformed:</p><div class="Body-module-scss-module__z40yvW__media-column Body-module-scss-module__z40yvW__inline"><div class="CodeBlock-module-scss-module__PbWBnq__codeBlock"><pre class="" style="--height:300px;--height-expanded:0px"><code class="plaintext">original_chunk = &quot;The company&#x27;s revenue grew by 3% over the previous quarter.&quot;

contextualized_chunk = &quot;This chunk is from an SEC filing on ACME corp&#x27;s performance in Q2 2023; the previous quarter&#x27;s revenue was $314 million. The company&#x27;s revenue grew by 3% over the previous quarter.&quot;</code></pre><div class="CodeBlock-module-scss-module__PbWBnq__controls"><button aria-label="Copy code"><svg class="Icon-module-scss-module__lqbdHG__icon" width="11" height="15" viewBox="0 0 11 15"><path d="M5.4 0C6.39875 0 7.26819 0.543814 7.73525 1.35H9.45C10.1956 1.35 10.8 1.95442 10.8 2.7V13.5C10.8 14.2456 10.1956 14.85 9.45 14.85H1.35C0.604415 14.85 2.17436e-08 14.2456 0 13.5V2.7C1.7395e-07 1.95442 0.604415 1.35 1.35 1.35H3.06475C3.53181 0.543814 4.40125 0 5.4 0ZM1.35 2.25C1.10147 2.25 0.9 2.45147 0.9 2.7V13.5C0.9 13.7485 1.10147 13.95 1.35 13.95H9.45C9.69853 13.95 9.9 13.7485 9.9 13.5V2.7C9.9 2.45147 9.69853 2.25 9.45 2.25H8.06221C8.08677 2.39637 8.1 2.54665 8.1 2.7V3.6C8.1 3.84853 7.89853 4.05 7.65 4.05H3.15C2.90147 4.05 2.7 3.84853 2.7 3.6V2.7C2.7 2.54665 2.71323 2.39637 2.73779 2.25H1.35ZM7.68603 10.6233C7.78376 10.395 8.04828 10.2886 8.27666 10.386C8.50499 10.4838 8.61143 10.7483 8.51396 10.9767C8.24856 11.5967 7.73014 12.15 7.01982 12.15C6.58192 12.1499 6.21722 11.9397 5.93965 11.6332C5.66215 11.9395 5.29801 12.1499 4.86035 12.15C4.42229 12.15 4.05692 11.9398 3.7793 11.6332C3.50175 11.9395 3.13773 12.15 2.7 12.15C2.45147 12.15 2.25 11.9485 2.25 11.7C2.25 11.4515 2.45147 11.25 2.7 11.25C2.8912 11.25 3.16726 11.0879 3.36621 10.6233L3.39697 10.5636C3.47806 10.4321 3.62261 10.35 3.78018 10.35C3.9602 10.3501 4.1233 10.4578 4.19414 10.6233C4.39309 11.0878 4.66917 11.25 4.86035 11.25C5.05156 11.2498 5.32773 11.0877 5.52656 10.6233L5.55732 10.5636C5.63837 10.4323 5.78229 10.3501 5.93965 10.35C6.11974 10.35 6.28275 10.4578 6.35361 10.6233C6.55251 11.0878 6.82862 11.2499 7.01982 11.25C7.21102 11.25 7.48708 11.0879 7.68603 10.6233ZM7.68603 7.02334C7.78376 6.79501 8.04828 6.68857 8.27666 6.78604C8.50499 6.88376 8.61143 7.14828 8.51396 7.37666C8.24856 7.99675 7.73014 8.55 7.01982 8.55C6.58192 8.54994 6.21722 8.3397 5.93965 8.0332C5.66215 8.33947 5.29801 8.54989 4.86035 8.55C4.42229 8.55 4.05692 8.33983 3.7793 8.0332C3.50175 8.33945 3.13773 8.55 2.7 8.55C2.45147 8.55 2.25 8.34853 2.25 8.1C2.25 7.85147 2.45147 7.65 2.7 7.65C2.8912 7.65 3.16726 7.48791 3.36621 7.02334L3.39697 6.96357C3.47806 6.83213 3.62261 6.75 3.78018 6.75C3.9602 6.75007 4.1233 6.85783 4.19414 7.02334C4.39309 7.48782 4.66917 7.65 4.86035 7.65C5.05156 7.6498 5.32773 7.48772 5.52656 7.02334L5.55732 6.96357C5.63837 6.83232 5.78229 6.75012 5.93965 6.75C6.11974 6.75 6.28275 6.85778 6.35361 7.02334C6.55251 7.48782 6.82862 7.6499 7.01982 7.65C7.21102 7.65 7.48708 7.48786 7.68603 7.02334ZM5.4 0.9C4.40589 0.9 3.6 1.70589 3.6 2.7V3.15H7.2V2.7C7.2 1.70589 6.39411 0.9 5.4 0.9Z" fill="currentColor"></path></svg><span class="body-3">Copy</span></button></div></div></div><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">It is worth noting that other approaches to using context to improve retrieval have been proposed in the past. Other proposals include: <a href="https://aclanthology.org/W02-0405.pdf">adding generic document summaries to chunks</a> (we experimented and saw very limited gains), <a href="https://arxiv.org/abs/2212.10496">hypothetical document embedding</a>, and <a href="https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec">summary-based indexing</a> (we evaluated and saw low performance). These methods differ from what is proposed in this post.</p><h3 class="Body-module-scss-module__z40yvW__reading-column headline-5 post-section" id="implementing-contextual-retrieval">Implementing Contextual Retrieval</h3><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Of course, it would be far too much work to manually annotate the thousands or even millions of chunks in a knowledge base. To implement Contextual Retrieval, we turn to Claude. We’ve written a prompt that instructs the model to provide concise, chunk-specific context that explains the chunk using the context of the overall document. We used the following Claude 3 Haiku prompt to generate context for each chunk:</p><div class="Body-module-scss-module__z40yvW__media-column Body-module-scss-module__z40yvW__inline"><div class="CodeBlock-module-scss-module__PbWBnq__codeBlock"><pre class="" style="--height:300px;--height-expanded:0px"><code class="plaintext">&lt;document&gt; 
{{WHOLE_DOCUMENT}} 
&lt;/document&gt; 
Here is the chunk we want to situate within the whole document 
&lt;chunk&gt; 
{{CHUNK_CONTENT}} 
&lt;/chunk&gt; 
Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else. </code></pre><div class="CodeBlock-module-scss-module__PbWBnq__controls"><button aria-label="Copy code"><svg class="Icon-module-scss-module__lqbdHG__icon" width="11" height="15" viewBox="0 0 11 15"><path d="M5.4 0C6.39875 0 7.26819 0.543814 7.73525 1.35H9.45C10.1956 1.35 10.8 1.95442 10.8 2.7V13.5C10.8 14.2456 10.1956 14.85 9.45 14.85H1.35C0.604415 14.85 2.17436e-08 14.2456 0 13.5V2.7C1.7395e-07 1.95442 0.604415 1.35 1.35 1.35H3.06475C3.53181 0.543814 4.40125 0 5.4 0ZM1.35 2.25C1.10147 2.25 0.9 2.45147 0.9 2.7V13.5C0.9 13.7485 1.10147 13.95 1.35 13.95H9.45C9.69853 13.95 9.9 13.7485 9.9 13.5V2.7C9.9 2.45147 9.69853 2.25 9.45 2.25H8.06221C8.08677 2.39637 8.1 2.54665 8.1 2.7V3.6C8.1 3.84853 7.89853 4.05 7.65 4.05H3.15C2.90147 4.05 2.7 3.84853 2.7 3.6V2.7C2.7 2.54665 2.71323 2.39637 2.73779 2.25H1.35ZM7.68603 10.6233C7.78376 10.395 8.04828 10.2886 8.27666 10.386C8.50499 10.4838 8.61143 10.7483 8.51396 10.9767C8.24856 11.5967 7.73014 12.15 7.01982 12.15C6.58192 12.1499 6.21722 11.9397 5.93965 11.6332C5.66215 11.9395 5.29801 12.1499 4.86035 12.15C4.42229 12.15 4.05692 11.9398 3.7793 11.6332C3.50175 11.9395 3.13773 12.15 2.7 12.15C2.45147 12.15 2.25 11.9485 2.25 11.7C2.25 11.4515 2.45147 11.25 2.7 11.25C2.8912 11.25 3.16726 11.0879 3.36621 10.6233L3.39697 10.5636C3.47806 10.4321 3.62261 10.35 3.78018 10.35C3.9602 10.3501 4.1233 10.4578 4.19414 10.6233C4.39309 11.0878 4.66917 11.25 4.86035 11.25C5.05156 11.2498 5.32773 11.0877 5.52656 10.6233L5.55732 10.5636C5.63837 10.4323 5.78229 10.3501 5.93965 10.35C6.11974 10.35 6.28275 10.4578 6.35361 10.6233C6.55251 11.0878 6.82862 11.2499 7.01982 11.25C7.21102 11.25 7.48708 11.0879 7.68603 10.6233ZM7.68603 7.02334C7.78376 6.79501 8.04828 6.68857 8.27666 6.78604C8.50499 6.88376 8.61143 7.14828 8.51396 7.37666C8.24856 7.99675 7.73014 8.55 7.01982 8.55C6.58192 8.54994 6.21722 8.3397 5.93965 8.0332C5.66215 8.33947 5.29801 8.54989 4.86035 8.55C4.42229 8.55 4.05692 8.33983 3.7793 8.0332C3.50175 8.33945 3.13773 8.55 2.7 8.55C2.45147 8.55 2.25 8.34853 2.25 8.1C2.25 7.85147 2.45147 7.65 2.7 7.65C2.8912 7.65 3.16726 7.48791 3.36621 7.02334L3.39697 6.96357C3.47806 6.83213 3.62261 6.75 3.78018 6.75C3.9602 6.75007 4.1233 6.85783 4.19414 7.02334C4.39309 7.48782 4.66917 7.65 4.86035 7.65C5.05156 7.6498 5.32773 7.48772 5.52656 7.02334L5.55732 6.96357C5.63837 6.83232 5.78229 6.75012 5.93965 6.75C6.11974 6.75 6.28275 6.85778 6.35361 7.02334C6.55251 7.48782 6.82862 7.6499 7.01982 7.65C7.21102 7.65 7.48708 7.48786 7.68603 7.02334ZM5.4 0.9C4.40589 0.9 3.6 1.70589 3.6 2.7V3.15H7.2V2.7C7.2 1.70589 6.39411 0.9 5.4 0.9Z" fill="currentColor"></path></svg><span class="body-3">Copy</span></button></div></div></div><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">The resulting contextual text, usually 50-100 tokens, is prepended to the chunk before embedding it and before creating the BM25 index.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Here’s what the preprocessing flow looks like in practice:</p><div class="Body-module-scss-module__z40yvW__media-column Body-module-scss-module__z40yvW__inline"><figure class="ImageWithCaption-module-scss-module__Duq99q__e-imageWithCaption"><img loading="lazy" width="3840" height="2160" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F2496e7c6fedd7ffaa043895c23a4089638b0c21b-3840x2160.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F2496e7c6fedd7ffaa043895c23a4089638b0c21b-3840x2160.png&amp;w=3840&amp;q=75"/><figcaption class="caption"><em>Contextual Retrieval is a preprocessing technique that improves retrieval accuracy.</em><br/></figcaption></figure></div><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">If you’re interested in using Contextual Retrieval, you can get started with <a href="https://platform.claude.com/cookbook/capabilities-contextual-embeddings-guide" target="_blank" rel="noopener noreferrer">our cookbook</a>.</p><h3 class="Body-module-scss-module__z40yvW__reading-column headline-5 post-section" id="using-prompt-caching-to-reduce-the-costs-of-contextual-retrieval">Using Prompt Caching to reduce the costs of Contextual Retrieval</h3><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Contextual Retrieval is uniquely possible at low cost with Claude, thanks to the special prompt caching feature we mentioned above. With prompt caching, you don’t need to pass in the reference document for every chunk. You simply load the document into the cache once and then reference the previously cached content. Assuming 800 token chunks, 8k token documents, 50 token context instructions, and 100 tokens of context per chunk, <strong>the one-time cost to generate contextualized chunks is $1.02 per million document tokens</strong>.</p><h4 class="Body-module-scss-module__z40yvW__reading-column headline-6 post-subsection" id="methodology">Methodology</h4><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">We experimented across various knowledge domains (codebases, fiction, ArXiv papers, Science Papers), embedding models, retrieval strategies, and evaluation metrics. We’ve included a few examples of the questions and answers we used for each domain in <a href="https://assets.anthropic.com/m/1632cded0a125333/original/Contextual-Retrieval-Appendix-2.pdf">Appendix II</a>.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">The graphs below show the average performance across all knowledge domains with the top-performing embedding configuration (Gemini Text 004) and retrieving the top-20-chunks. We use 1 minus recall@20 as our evaluation metric, which measures the percentage of relevant documents that fail to be retrieved within the top 20 chunks. You can see the full results in the appendix - contextualizing improves performance in every embedding-source combination we evaluated.</p><h4 class="Body-module-scss-module__z40yvW__reading-column headline-6 post-subsection" id="performance-improvements">Performance improvements</h4><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Our experiments showed that:</p><ul class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text"><li><strong>Contextual Embeddings reduced the top-20-chunk retrieval failure rate by 35%</strong> (5.7% → 3.7%).</li><li><strong>Combining Contextual Embeddings and Contextual BM25 reduced the top-20-chunk retrieval failure rate by 49%</strong> (5.7% → 2.9%).</li></ul><div class="Body-module-scss-module__z40yvW__media-column Body-module-scss-module__z40yvW__inline"><figure class="ImageWithCaption-module-scss-module__Duq99q__e-imageWithCaption"><img loading="lazy" width="3840" height="2160" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7f8d739e491fe6b3ba0e6a9c74e4083d760b88c9-3840x2160.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7f8d739e491fe6b3ba0e6a9c74e4083d760b88c9-3840x2160.png&amp;w=3840&amp;q=75"/><figcaption class="caption"><em>Combining Contextual Embedding and Contextual BM25 reduce the top-20-chunk retrieval failure rate by 49%.</em></figcaption></figure></div><h4 class="Body-module-scss-module__z40yvW__reading-column headline-6 post-subsection" id="implementation-considerations">Implementation considerations</h4><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">When implementing Contextual Retrieval, there are a few considerations to keep in mind:</p><ol class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text"><li><strong>Chunk boundaries:</strong> Consider how you split your documents into chunks. The choice of chunk size, chunk boundary, and chunk overlap can affect retrieval performance<sup class="caption Body-module-scss-module__z40yvW__sup">1</sup>.</li><li><strong>Embedding model:</strong> Whereas Contextual Retrieval improves performance across all embedding models we tested, some models may benefit more than others. We found <a href="https://ai.google.dev/gemini-api/docs/embeddings">Gemini</a> and <a href="https://www.voyageai.com/">Voyage</a> embeddings to be particularly effective.</li><li><strong>Custom contextualizer prompts:</strong> While the generic prompt we provided works well, you may be able to achieve even better results with prompts tailored to your specific domain or use case (for example, including a glossary of key terms that might only be defined in other documents in the knowledge base).</li><li><strong>Number of chunks:</strong> Adding more chunks into the context window increases the chances that you include the relevant information. However, more information can be distracting for models so there&#x27;s a limit to this. We tried delivering 5, 10, and 20 chunks, and found using 20 to be the most performant of these options (see appendix for comparisons) but it’s worth experimenting on your use case.</li></ol><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text"><strong>Always run evals: </strong>Response generation may be improved by passing it the contextualized chunk and distinguishing between what is context and what is the chunk.</p><h2 class="Body-module-scss-module__z40yvW__reading-column headline-4 post-heading" id="further-boosting-performance-with-reranking">Further boosting performance with Reranking</h2><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">In a final step, we can combine Contextual Retrieval with another technique to give even more performance improvements. In traditional RAG, the AI system searches its knowledge base to find the potentially relevant information chunks. With large knowledge bases, this initial retrieval often returns a lot of chunks—sometimes hundreds—of varying relevance and importance.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Reranking is a commonly used filtering technique to ensure that only the most relevant chunks are passed to the model. Reranking provides better responses and reduces cost and latency because the model is processing less information. The key steps are:</p><ol class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text"><li>Perform initial retrieval to get the top potentially relevant chunks (we used the top 150);</li><li>Pass the top-N chunks, along with the user&#x27;s query, through the reranking model;</li><li>Using a reranking model, give each chunk a score based on its relevance and importance to the prompt, then select the top-K chunks (we used the top 20);</li><li>Pass the top-K chunks into the model as context to generate the final result.</li></ol><div class="Body-module-scss-module__z40yvW__media-column Body-module-scss-module__z40yvW__inline"><figure class="ImageWithCaption-module-scss-module__Duq99q__e-imageWithCaption"><img loading="lazy" width="3840" height="2160" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8f82c6175a64442ceff4334b54fac2ab3436a1d1-3840x2160.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8f82c6175a64442ceff4334b54fac2ab3436a1d1-3840x2160.png&amp;w=3840&amp;q=75"/><figcaption class="caption"><em>Combine Contextual Retrieva and Reranking to maximize retrieval accuracy.</em></figcaption></figure></div><h3 class="Body-module-scss-module__z40yvW__reading-column headline-5 post-section" id="performance-improvements">Performance improvements</h3><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">There are several reranking models on the market. We ran our tests with the <a href="https://cohere.com/rerank">Cohere reranker</a>. Voyage<a href="https://docs.voyageai.com/docs/reranker"> also offers a reranker</a>, though we did not have time to test it. Our experiments showed that, across various domains, adding a reranking step further optimizes retrieval.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Specifically, we found that Reranked Contextual Embedding and Contextual BM25 reduced the top-20-chunk retrieval failure rate by 67% (5.7% → 1.9%).</p><div class="Body-module-scss-module__z40yvW__media-column Body-module-scss-module__z40yvW__inline"><figure class="ImageWithCaption-module-scss-module__Duq99q__e-imageWithCaption"><img loading="lazy" width="3840" height="2160" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F93a70cfbb7cca35bb8d86ea0a23bdeeb699e8e58-3840x2160.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F93a70cfbb7cca35bb8d86ea0a23bdeeb699e8e58-3840x2160.png&amp;w=3840&amp;q=75"/><figcaption class="caption"><em>Reranked Contextual Embedding and Contextual BM25 reduces the top-20-chunk retrieval failure rate by 67%.</em></figcaption></figure></div><h4 class="Body-module-scss-module__z40yvW__reading-column headline-6 post-subsection" id="cost-and-latency-considerations">Cost and latency considerations</h4><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">One important consideration with reranking is the impact on latency and cost, especially when reranking a large number of chunks. Because reranking adds an extra step at runtime, it inevitably adds a small amount of latency, even though the reranker scores all the chunks in parallel. There is an inherent trade-off between reranking more chunks for better performance vs. reranking fewer for lower latency and cost. We recommend experimenting with different settings on your specific use case to find the right balance.</p><h2 class="Body-module-scss-module__z40yvW__reading-column headline-4 post-heading" id="conclusion">Conclusion</h2><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">We ran a large number of tests, comparing different combinations of all the techniques described above (embedding model, use of BM25, use of contextual retrieval, use of a reranker, and total # of top-K results retrieved), all across a variety of different dataset types. Here’s a summary of what we found:</p><ol class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text"><li>Embeddings+BM25 is better than embeddings on their own;</li><li>Voyage and Gemini have the best embeddings of the ones we tested;</li><li>Passing the top-20 chunks to the model is more effective than just the top-10 or top-5;</li><li>Adding context to chunks improves retrieval accuracy a lot;</li><li>Reranking is better than no reranking;</li><li><strong>All these benefits stack</strong>: to maximize performance improvements, we can combine contextual embeddings (from Voyage or Gemini) with contextual BM25, plus a reranking step, and adding the 20 chunks to the prompt.</li></ol><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">We encourage all developers working with knowledge bases to use <a href="https://platform.claude.com/cookbook/capabilities-contextual-embeddings-guide" target="_blank" rel="noopener noreferrer">our cookbook</a> to experiment with these approaches to unlock new levels of performance.</p><h2 class="Body-module-scss-module__z40yvW__reading-column headline-4 post-heading" id="appendix-i">Appendix I</h2><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Below is a breakdown of results across datasets, embedding providers, use of BM25 in addition to embeddings, use of contextual retrieval, and use of reranking for Retrievals @ 20.</p><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">See <a href="https://assets.anthropic.com/m/1632cded0a125333/original/Contextual-Retrieval-Appendix-2.pdf">Appendix II</a> for the breakdowns for Retrievals @ 10 and @ 5 as well as example questions and answers for each dataset.</p><div class="Body-module-scss-module__z40yvW__media-column Body-module-scss-module__z40yvW__inline"><figure class="ImageWithCaption-module-scss-module__Duq99q__e-imageWithCaption"><img loading="lazy" width="2458" height="2983" decoding="async" data-nimg="1" style="color:transparent" srcSet="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F646a894ec4e6120cade9951a362f685cd2ec89b2-2458x2983.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F646a894ec4e6120cade9951a362f685cd2ec89b2-2458x2983.png&amp;w=3840&amp;q=75"/><figcaption class="caption"><em>1 minus recall @ 20 results across data sets and embedding providers.</em></figcaption></figure></div><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text"></p><h2 class="Body-module-scss-module__z40yvW__reading-column headline-4 post-heading" id="acknowledgements-">Acknowledgements </h2><p class="Body-module-scss-module__z40yvW__reading-column body-2 serif post-text">Research and writing by Daniel Ford. Thanks to Orowa Sikder, Gautam Mittal, and Kenneth Lien for critical feedback, Samuel Flamini for implementing the cookbooks, Lauren Polansky for project coordination and Alex Albert, Susan Payne, Stuart Ritchie, and Brad Abrams for shaping this blog post.</p></div></div></article><div class="NewsletterEngineering-module-scss-module__AiizZa__wrapper"><div class="NewsletterEngineering-module-scss-module__AiizZa__content"><div class="NewsletterEngineering-module-scss-module__AiizZa__textContent"><h2 class="headline-5 NewsletterEngineering-module-scss-module__AiizZa__title">Get the developer newsletter</h2><div class="NewsletterEngineering-module-scss-module__AiizZa__body"><p class="body-1 serif tight">Product updates, how-tos, community spotlights, and more. Delivered monthly to your inbox.</p></div></div><div class="NewsletterEngineering-module-scss-module__AiizZa__formContainer"><form class="NewsletterEngineering-module-scss-module__AiizZa__emailForm"><div class="NewsletterEngineering-module-scss-module__AiizZa__inputWrapper"><input type="email" placeholder="Enter your email" class="NewsletterEngineering-module-scss-module__AiizZa__emailInput" required="" name="email" value=""/><button type="submit" class="NewsletterEngineering-module-scss-module__AiizZa__submitButton"><svg class="Icon-module-scss-module__lqbdHG__icon" width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="#ffffff"></path></svg></button></div><p class="body-3">Please provide your email address if you’d like to receive our monthly developer newsletter. You can unsubscribe at any time.</p></form></div></div></div></div></main><footer id="footer" class="SiteFooter-module-scss-module__JdOqwq__root" role="contentinfo" aria-label="Site footer"><div class="page-wrapper SiteFooter-module-scss-module__JdOqwq__footer"><div class="SiteFooter-module-scss-module__JdOqwq__logoWrapper"><a href="/" aria-label="Return to homepage"><svg class="Icon-module-scss-module__lqbdHG__icon" width="46" height="32" viewBox="0 0 46 32"><path d="M32.73 0h-6.945L38.45 32h6.945L32.73 0ZM12.665 0 0 32h7.082l2.59-6.72h13.25l2.59 6.72h7.082L19.929 0h-7.264Zm-.702 19.337 4.334-11.246 4.334 11.246h-8.668Z" fill="#faf9f5"></path></svg></a></div><nav class="SiteFooter-module-scss-module__JdOqwq__linksWrapper" aria-label="Footer navigation"><div class="SiteFooter-module-scss-module__JdOqwq__columnSection"><div class="SiteFooter-module-scss-module__JdOqwq__listSection"><h3 class="body-2 bold">Products</h3><ul class="SiteFooter-module-scss-module__JdOqwq__list"><li><a href="https://claude.com/product/overview" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Claude</a></li><li><a href="https://claude.com/product/claude-code" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Claude Code</a></li><li><a href="https://claude.com/product/cowork" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Cowork</a></li><li><a href="https://claude.com/chrome" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Claude in Chrome</a></li><li><a href="https://claude.com/claude-in-excel" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Claude in Excel</a></li><li><a href="https://claude.com/claude-in-powerpoint" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Claude in PowerPoint</a></li><li><a href="https://claude.com/claude-in-slack" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Claude in Slack</a></li><li><a href="https://www.claude.com/skills" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Skills</a></li><li><a href="https://claude.com/pricing/max" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Max plan</a></li><li><a href="https://claude.com/pricing/team" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Team plan</a></li><li><a href="https://claude.com/pricing/enterprise" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Enterprise plan</a></li><li><a href="https://claude.ai/download" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Download app</a></li><li><a href="https://claude.com/pricing" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Pricing</a></li><li><a href="https://claude.ai/" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Log in to Claude</a></li></ul></div><div class="SiteFooter-module-scss-module__JdOqwq__listSection"><h3 class="body-2 bold">Models</h3><ul class="SiteFooter-module-scss-module__JdOqwq__list"><li><a href="/www.anthropic.com/claude/opus" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Opus</a></li><li><a href="/www.anthropic.com/claude/sonnet" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Sonnet</a></li><li><a href="/www.anthropic.com/claude/haiku" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Haiku</a></li></ul></div></div><div class="SiteFooter-module-scss-module__JdOqwq__columnSection"><div class="SiteFooter-module-scss-module__JdOqwq__listSection"><h3 class="body-2 bold">Solutions</h3><ul class="SiteFooter-module-scss-module__JdOqwq__list"><li><a href="https://claude.com/solutions/agents" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">AI agents</a></li><li><a href="https://claude.com/solutions/code-modernization" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Code modernization</a></li><li><a href="https://claude.com/solutions/coding" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Coding</a></li><li><a href="https://claude.com/solutions/customer-support" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Customer support</a></li><li><a href="https://claude.com/solutions/education" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Education</a></li><li><a href="https://claude.com/solutions/financial-services" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Financial services</a></li><li><a href="https://claude.com/solutions/government" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Government</a></li><li><a href="https://claude.com/solutions/healthcare" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Healthcare</a></li><li><a href="https://claude.com/solutions/life-sciences" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Life sciences</a></li><li><a href="https://claude.com/solutions/nonprofits" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Nonprofits</a></li></ul></div><div class="SiteFooter-module-scss-module__JdOqwq__listSection"><h3 class="body-2 bold">Claude Developer Platform</h3><ul class="SiteFooter-module-scss-module__JdOqwq__list"><li><a href="https://claude.com/platform/api" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Overview</a></li><li><a href="https://platform.claude.com/docs" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Developer docs</a></li><li><a href="https://claude.com/pricing#api" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Pricing</a></li><li><a href="https://claude.com/regional-compliance" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Regional compliance</a></li><li><a href="https://claude.com/partners/amazon-bedrock" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Amazon Bedrock</a></li><li><a href="https://claude.com/partners/google-cloud-vertex-ai" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Google Cloud’s Vertex AI</a></li><li><a href="https://platform.claude.com/" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Console login</a></li></ul></div></div><div class="SiteFooter-module-scss-module__JdOqwq__columnSection"><div class="SiteFooter-module-scss-module__JdOqwq__listSection"><h3 class="body-2 bold">Learn</h3><ul class="SiteFooter-module-scss-module__JdOqwq__list"><li><a href="https://claude.com/blog" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Blog</a></li><li><a href="https://claude.com/partners" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Claude partner network</a></li><li><a href="https://claude.com/connectors" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Connectors</a></li><li><a href="/learn" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Courses</a></li><li><a href="https://claude.com/customers" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Customer stories</a></li><li><a href="/engineering" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Engineering at Anthropic</a></li><li><a href="/events" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Events</a></li><li><a href="https://claude.com/plugins" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Plugins</a></li><li><a href="https://claude.com/partners/powered-by-claude" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Powered by Claude</a></li><li><a href="https://claude.com/partners/services" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Service partners</a></li><li><a href="https://claude.com/programs/startups" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Startups program</a></li><li><a href="https://claude.com/resources/tutorials" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Tutorials</a></li><li><a href="https://claude.com/resources/use-cases" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Use cases</a></li></ul></div><div class="SiteFooter-module-scss-module__JdOqwq__listSection"><h3 class="body-2 bold">Company</h3><ul class="SiteFooter-module-scss-module__JdOqwq__list"><li><a href="/company" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Anthropic</a></li><li><a href="/careers" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Careers</a></li><li><a href="/economic-index" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Economic Futures</a></li><li><a href="/research" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Research</a></li><li><a href="/news" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">News</a></li><li><a href="/constitution" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Claude’s Constitution</a></li><li><a href="/www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Responsible Scaling Policy</a></li><li><a href="https://trust.anthropic.com/" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Security and compliance</a></li><li><a href="/transparency" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Transparency</a></li></ul></div></div><div class="SiteFooter-module-scss-module__JdOqwq__columnSection"><div class="SiteFooter-module-scss-module__JdOqwq__listSection"><h3 class="body-2 bold">Help and security</h3><ul class="SiteFooter-module-scss-module__JdOqwq__list"><li><a href="/www.anthropic.com/supported-countries" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Availability</a></li><li><a href="https://status.anthropic.com/" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Status</a></li><li><a href="https://support.claude.com/en/" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2" target="_blank" rel="noopener noreferrer">Support center</a></li></ul></div><div class="SiteFooter-module-scss-module__JdOqwq__listSection"><h3 class="body-2 bold">Terms and policies</h3><ul class="SiteFooter-module-scss-module__JdOqwq__list"><li><a href="/www.anthropic.com/legal/privacy" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Privacy policy</a></li><li><a href="/www.anthropic.com/legal/consumer-health-data-privacy-policy" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Consumer health data privacy policy</a></li><li><a href="/www.anthropic.com/responsible-disclosure-policy" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Responsible disclosure policy</a></li><li><a href="/www.anthropic.com/legal/commercial-terms" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Terms of service: Commercial</a></li><li><a href="/www.anthropic.com/legal/consumer-terms" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Terms of service: Consumer</a></li><li><a href="/www.anthropic.com/legal/aup" class="SiteFooter-module-scss-module__JdOqwq__listItem body-2">Usage policy</a></li></ul></div></div></nav><div class="SiteFooter-module-scss-module__JdOqwq__socialWrapper"><small class="body-2 SiteFooter-module-scss-module__JdOqwq__copyright" role="contentinfo">© 2026 Anthropic PBC</small><ul class="SiteFooter-module-scss-module__JdOqwq__socialIcons" role="navigation" aria-label="Social media links"><li><a href="https://www.linkedin.com/company/anthropicresearch" aria-label="Visit our LinkedIn page" target="_blank" rel="noopener noreferrer"><svg class="Icon-module-scss-module__lqbdHG__icon" width="24" height="24" viewBox="0 0 32 32"><path d="M25.8182 4H6.18182C4.97636 4 4 4.97636 4 6.18182V25.8182C4 27.0236 4.97636 28 6.18182 28H25.8182C27.0236 28 28 27.0236 28 25.8182V6.18182C28 4.97636 27.0236 4 25.8182 4ZM11.5862 23.6364H8.368V13.2815H11.5862V23.6364ZM9.94436 11.8011C8.90691 11.8011 8.068 10.96 8.068 9.92473C8.068 8.88945 8.908 8.04945 9.94436 8.04945C10.9785 8.04945 11.8196 8.89055 11.8196 9.92473C11.8196 10.96 10.9785 11.8011 9.94436 11.8011ZM23.6407 23.6364H20.4247V18.6007C20.4247 17.3996 20.4029 15.8549 18.7524 15.8549C17.0778 15.8549 16.8204 17.1629 16.8204 18.5135V23.6364H13.6044V13.2815H16.6916V14.6964H16.7353C17.1651 13.8825 18.2145 13.024 19.78 13.024C23.0385 13.024 23.6407 15.1687 23.6407 17.9571V23.6364Z" fill="#b0aea5"></path></svg></a></li><li><a href="https://x.com/AnthropicAI" aria-label="Visit our X (formerly Twitter) profile" target="_blank" rel="noopener noreferrer"><svg class="Icon-module-scss-module__lqbdHG__icon" width="24" height="24" viewBox="0 0 32 32"><path d="M28 28L18.6145 14.0124L18.6305 14.0255L27.0929 4H24.265L17.3713 12.16L11.8968 4H4.48021L13.2425 17.0593L13.2414 17.0582L4 28H6.82792L14.4921 18.9215L20.5834 28H28ZM10.7763 6.18182L23.9449 25.8182H21.7039L8.52468 6.18182H10.7763Z" fill="#b0aea5"></path></svg></a></li><li><a href="https://www.youtube.com/@anthropic-ai" aria-label="Visit our YouTube channel" target="_blank" rel="noopener noreferrer"><svg class="Icon-module-scss-module__lqbdHG__icon" width="24" height="24" viewBox="0 0 32 32"><path d="M29.2184 9.4375C28.9596 8.06299 27.7263 7.06201 26.2951 6.74951C24.1533 6.3125 20.1896 6 15.901 6C11.615 6 7.58782 6.3125 5.44354 6.74951C4.01486 7.06201 2.77905 7.99951 2.52021 9.4375C2.25884 11 2 13.1875 2 16C2 18.8125 2.25884 21 2.58365 22.5625C2.84502 23.937 4.0783 24.938 5.50698 25.2505C7.78068 25.6875 11.6784 26 15.967 26C20.2556 26 24.1533 25.6875 26.427 25.2505C27.8557 24.938 29.089 24.0005 29.3504 22.5625C29.6092 21 29.934 18.749 30 16C29.868 13.1875 29.5432 11 29.2184 9.4375ZM12.3941 20.375V11.625L20.319 16L12.3941 20.375Z" fill="#b0aea5"></path></svg></a></li></ul></div></div></footer><!--$?--><template id="B:1"></template><!--/$--><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">requestAnimationFrame(function(){$RT=performance.now()});</script><script src="/_next/static/chunks/f4386f5ba7642880.js" nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz" id="_R_" async=""></script><title>Contextual Retrieval in AI Systems \ Anthropic</title><meta name="description" content="Explore how Anthropic enhances AI systems through advanced contextual retrieval methods. Learn about our approach to improving information access and relevance in large language models."/><meta name="msapplication-TileColor" content="141413"/><meta name="msapplication-config" content="/browserconfig.xml"/><meta property="og:title" content="Contextual Retrieval in AI Systems"/><meta property="og:description" content="Explore how Anthropic enhances AI systems through advanced contextual retrieval methods. Learn about our approach to improving information access and relevance in large language models."/><meta property="og:image" content="https://cdn.sanity.io/images/4zrzovbb/website/2bb957622142f53575f476f76473593fa89d1dc8-2400x1260.png"/><meta property="og:image:alt" content="Anthropic logo"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@AnthropicAI"/><meta name="twitter:creator" content="@AnthropicAI"/><meta name="twitter:title" content="Contextual Retrieval in AI Systems"/><meta name="twitter:description" content="Explore how Anthropic enhances AI systems through advanced contextual retrieval methods. Learn about our approach to improving information access and relevance in large language models."/><meta name="twitter:image" content="https://cdn.sanity.io/images/4zrzovbb/website/2bb957622142f53575f476f76473593fa89d1dc8-2400x1260.png"/><meta name="twitter:image:alt" content="Anthropic logo"/><link rel="shortcut icon" href="/favicon.ico"/><link rel="icon" href="/images/icons/favicon-32x32.png"/><link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png"/><link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png" sizes="180x180"/><link rel="mask-icon" href="/images/icons/safari-pinned-tab.svg" color="141413"/><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><div hidden id="S:0"></div><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">$RB=[];$RV=function(a){$RT=performance.now();for(var b=0;b<a.length;b+=2){var c=a[b],e=a[b+1];null!==e.parentNode&&e.parentNode.removeChild(e);var f=c.parentNode;if(f){var g=c.previousSibling,h=0;do{if(c&&8===c.nodeType){var d=c.data;if("/$"===d||"/&"===d)if(0===h)break;else h--;else"$"!==d&&"$?"!==d&&"$~"!==d&&"$!"!==d&&"&"!==d||h++}d=c.nextSibling;f.removeChild(c);c=d}while(c);for(;e.firstChild;)f.insertBefore(e.firstChild,c);g.data="$";g._reactRetry&&requestAnimationFrame(g._reactRetry)}}a.length=0};
$RC=function(a,b){if(b=document.getElementById(b))(a=document.getElementById(a))?(a.previousSibling.data="$~",$RB.push(a,b),2===$RB.length&&("number"!==typeof $RT?requestAnimationFrame($RV.bind(null,$RB)):(a=performance.now(),setTimeout($RV.bind(null,$RB),2300>a&&2E3<a?2300-a:$RT+300-a)))):b.parentNode.removeChild(b)};$RC("B:0","S:0")</script><div hidden id="S:1"></div><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">$RC("B:1","S:1")</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">(self.__next_f=self.__next_f||[]).push([0])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"1:\"$Sreact.fragment\"\n4:I[339756,[\"/_next/static/chunks/d96012bcfc98706a.js\",\"/_next/static/chunks/d80b3790a119a285.js\"],\"default\"]\n5:I[837457,[\"/_next/static/chunks/d96012bcfc98706a.js\",\"/_next/static/chunks/d80b3790a119a285.js\"],\"default\"]\na:I[168027,[\"/_next/static/chunks/d96012bcfc98706a.js\",\"/_next/static/chunks/d80b3790a119a285.js\"],\"default\"]\nb:I[897367,[\"/_next/static/chunks/d96012bcfc98706a.js\",\"/_next/static/chunks/d80b3790a119a285.js\"],\"OutletBoundary\"]\nc:\"$Sreact.suspense\"\ne:I[897367,[\"/_next/static/chunks/d96012bcfc98706a.js\",\"/_next/static/chunks/d80b3790a119a285.js\"],\"ViewportBoundary\"]\n10:I[897367,[\"/_next/static/chunks/d96012bcfc98706a.js\",\"/_next/static/chunks/d80b3790a119a285.js\"],\"MetadataBoundary\"]\n12:I[264900,[\"/_next/static/chunks/1fb574e7be3f9a05.js\",\"/_next/static/chunks/9a604444e87766dd.js\",\"/_next/static/chunks/c1896c986be1a2e2.js\"],\"default\"]\n13:I[649551,[\"/_next/static/chunks/1fb574e7be3f9a05.js\",\"/_next/static/chunks/9a604444e87766dd.js\",\"/_next/static/chunks/c1896c986be1a2e2.js\"],\"default\"]\n14:I[96155,[\"/_next/static/chunks/1fb574e7be3f9a05.js\",\"/_next/static/chunks/9a604444e87766dd.js\",\"/_next/static/chunks/c1896c986be1a2e2.js\"],\"default\"]\n16:I[775710,[\"/_next/static/chunks/1fb574e7be3f9a05.js\",\"/_next/static/chunks/9a604444e87766dd.js\",\"/_next/static/chunks/c1896c986be1a2e2.js\",\"/_next/static/chunks/f5a33d7993e253c8.js\",\"/_next/static/chunks/496bc8a289f448d1.js\",\"/_next/static/chunks/b1040bb2d2fbd1e5.js\",\"/_next/static/chunks/2e3229a62c65aaec.js\",\"/_next/static/chunks/5c1988096a7b174a.js\",\"/_next/static/chunks/f563a58c137d4bc2.js\",\"/_next/static/chunks/2fd2aa01a4bc9178.js\",\"/_next/static/chunks/630870b77208f43d.js\",\"/_next/static/chunks/010986693eb1c9c2.js\",\"/_next/static/chunks/dabacb64939959b3.js\",\"/_next/static/chunks/c0d75d4ca01ae43d.js\",\"/_next/static/chunks/6c680011ff6c5ba2.js\",\"/_next/static/chunks/81716bb24f5a6f8f.js\"],\"default\"]\n17:I[606617,[\"/_next/static/chunks/1fb574e7be3f9a05.js\",\"/_next/static/chunks/9a604444e87766dd.js\",\"/_next/static/chunks/c1896c986be1a2e2.js\",\"/_next/static/chunks/7c80d08c36d49463.js\",\"/_next/static/chunks/496bc8a289f448d1.js\",\"/_next/static/chunks/b1040bb2d2fbd1e5.js\",\"/_next/static/chunks/5c1988096a7b174a.js\",\"/_next/static/chunks/33647e5ba6496195.js\",\"/_next/static/chunks/667473da0b5c11bc.js\",\"/_next/static/chunks/2e3229a62c65aaec.js\",\"/_next/static/chunks/010986693eb1c9c2.js\",\"/_next/static/chunks/2c9eb3077aa18f16.js\",\"/_next/static/chunks/6c680011ff6c5ba2.js\",\"/_next/static/chunks/2fd2aa01a4bc9178.js\",\"/_next/static/chunks/630870b77208f43d.js\"],\"default\"]\n18:I[837061,[\"/_next/static/chunks/1fb574e7be3f9a05.js\",\"/_next/static/chunks/9a604444e87766dd.js\",\"/_next/static/chunks/c1896c986be1a2e2.js\",\"/_next/static/chunks/7c80d08c36d49463.js\",\"/_next/static/chunks/496bc8a289f448d1.js\",\"/_next/static/chunks/b1040bb2d2fbd1e5.js\",\"/_next/static/chunks/5c1988096a7b174a.js\",\"/_next/static/chunks/33647e5ba6496195.js\",\"/_next/static/chunks/667473da0b5c11bc.js\",\"/_next/static/chunks/2e3229a62c65aaec.js\",\"/_next/static/chunks/010986693eb1c9c2.js\",\"/_next/static/chunks/2c9eb3077aa18f16.js\",\"/_next/static/chunks/6c680011ff6c5ba2.js\",\"/_next/static/chunks/2fd2aa01a4bc9178.js\",\"/_next/static/chunks/630870b77208f43d.js\"],\"default\"]\n1a:I[307003,[\"/_next/static/chunks/1fb574e7be3f9a05.js\",\"/_next/static/chunks/9a604444e87766dd.js\",\"/_next/static/chunks/c1896c986be1a2e2.js\",\"/_next/static/chunks/7c80d08c36d49463.js\",\"/_next/static/chunks/496bc8a289f448d1.js\",\"/_next/static/chunks/b1040bb2d2fbd1e5.js\",\"/_next/static/chunks/5c1988096a7b174a.js\",\"/_next/static/chunks/33647e5ba6496195.js\",\"/_next/static/chunks/667473da0b5c11bc.js\",\"/_next/static/chunks/2e3229a62c65aaec.js\",\"/_next/static/chunks/010986693eb1c9c2.js\",\"/_next/static/chunks/2c9eb3077aa18f16.js\",\"/_next/static/chunks/6c680011ff6c5ba2.js\",\"/_next/static/chunks/2fd2aa01a4bc9178.js\",\"/_next/static/chunks/630870b77208f43d.js\"],\"default\"]\n1b:I[27201,[\"/_next/static/chunks/d96012bcfc98706a.js\",\"/_next/static/chunks/d80b3790a119a285.js\"],\"IconMark\"]\n:HL[\"/_next/static/chunks/ec368b341879b233.css\",\"style\",{\"nonce\":\"Y2ZjNWY"])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"xNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}]\n:HL[\"/_next/static/chunks/38fee8473f816a4a.css\",\"style\",{\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}]\n:HL[\"/_next/static/media/AnthropicMono_Italic_Web-s.p.154bb54e.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/AnthropicMono_Roman_Web-s.p.e2998bbe.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/AnthropicSans_Italic_Variable-s.p.dfc8e235.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/AnthropicSans_Roman_Variable-s.p.52cc3a10.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/AnthropicSerif_Italic_Variable-s.p.9d7ca5ec.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/AnthropicSerif_Roman_Variable-s.p.55835b1f.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/Copernicus_Book-s.p.f166c0ba.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/Copernicus_Medium-s.p.59728346.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/JetBrainsMono_VF-s.p.8dac7c36.ttf\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/ttf\"}]\n:HL[\"/_next/static/media/StyreneA_MediumItalic_Web-s.p.e9bc3c6e.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/StyreneA_Medium_Web-s.p.e5135f7e.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/StyreneA_RegularItalic_Web-s.p.7c6a646d.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/StyreneA_Regular_Web-s.p.429c699d.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/StyreneB_Medium_Web-s.p.88fa5a67.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/StyreneB_Regular_Web-s.p.cb3cc1a3.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/TiemposText_Medium-s.p.520d99f8.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/TiemposText_MediumItalic-s.p.10f44518.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/TiemposText_Regular-s.p.7f1d46d6.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/TiemposText_RegularItalic-s.p.1a798fcf.woff2\",\"font\",{\"crossOrigin\":\"\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/chunks/caf680e685668b99.css\",\"style\",{\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}]\n:HL[\"/_next/static/chunks/ad266d0a6bc656af.css\",\"style\",{\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}]\n:HL[\"/_next/static/chunks/e2c670ea67fc2bbb.css\",\"style\",{\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}]\n:HL[\"/_next/static/chunks/758311c654d998de.css\",\"style\",{\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}]\n:HL[\"/_next/static/chunks/7e4146583225b449.css\",\"style\",{\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}]\n"])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"0:{\"P\":null,\"b\":\"Ev1insoJIZ1ve_aUh7493\",\"c\":[\"\",\"engineering\",\"contextual-retrieval\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"(site)\",{\"children\":[\"engineering\",{\"children\":[[\"slug\",\"contextual-retrieval\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/ec368b341879b233.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}]],\"$L2\"]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/38fee8473f816a4a.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/1fb574e7be3f9a05.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/9a604444e87766dd.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-2\",{\"src\":\"/_next/static/chunks/c1896c986be1a2e2.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}]],\"$L3\"]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[\"$L6\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/caf680e685668b99.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/ad266d0a6bc656af.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/e2c670ea67fc2bbb.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"link\",\"3\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/758311c654d998de.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/f5a33d7993e253c8.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/496bc8a289f448d1.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-2\",{\"src\":\"/_next/static/chunks/b1040bb2d2fbd1e5.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-3\",{\"src\":\"/_next/static/chunks/2e3229a62c65aaec.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-4\",{\"src\":\"/_next/static/chunks/5c1988096a7b174a.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-5\",{\"src\":\"/_next/static/chunks/f563a58c137d4bc2.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-6\",{\"src\":\"/_next/static/chunks/2fd2aa01a4bc9178.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-7\",{\"src\":\"/_next/static/chunks/630870b77208f43d.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-8\",{\"src\":\"/_next/static/chunks/010986693eb1c9c2.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-9\",{\"src\":\"/_next/static/chunks/dabacb64939959b3.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-10\",{\"src\":\"/_next/static/chunks/c0d75d4ca01ae43d.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"script\",\"script-11\",{\"src\":\"/_next/static/chunks/6c680011ff6c5ba2.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],\"$L7\"],\"$L8\"]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false]},null,false,false],\"$L9\",false]],\"m\":\"$undefined\",\"G\":[\"$a\",[]],\"S\":false}\n"])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"7:[\"$\",\"script\",\"script-12\",{\"src\":\"/_next/static/chunks/81716bb24f5a6f8f.js\",\"async\":true,\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}]\n8:[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$c\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@d\"}]}]\n9:[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$Le\",null,{\"children\":\"$@f\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$L10\",null,{\"children\":[\"$\",\"$c\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@11\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]\n"])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"2:[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"anthropicsans_eac0b31f-module__tjnuGq__variable anthropicserif_87b6fa7d-module__quIBbW__variable anthropicmono_fae19af3-module__c5XAsG__variable copernicus_4da799c5-module__dijTSq__variable styrenea_f8492ab1-module__HimLXW__variable styreneb_278af5c6-module__wkOAdG__variable tiempostext_4eff4b4c-module__mpviCW__variable jetbrainsmono_7d7bdbc6-module__j_XgJq__variable\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]\n"])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"3:[\"$\",\"$L12\",null,{\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\",\"children\":[\"$\",\"$L13\",null,{\"gpcDetected\":false,\"children\":[[\"$\",\"$L14\",null,{}],[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$L15\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/caf680e685668b99.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/ad266d0a6bc656af.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"link\",\"2\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/e2c670ea67fc2bbb.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}],[\"$\",\"link\",\"3\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/7e4146583225b449.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz\"}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]}]\n"])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"6:[\"$\",\"$L16\",null,{\"article\":{\"_createdAt\":\"2025-01-06T16:57:14Z\",\"_id\":\"54903db4-4dbb-4afc-bbcf-d0d3de7aa8f1\",\"_rev\":\"ggOzj4NNHCLk615ct1CfPI\",\"_system\":{\"base\":{\"id\":\"54903db4-4dbb-4afc-bbcf-d0d3de7aa8f1\",\"rev\":\"K6iz3y2GzCYbtUtEuZHifI\"}},\"_type\":\"engineeringArticle\",\"_updatedAt\":\"2026-01-07T15:00:44Z\",\"body\":[{\"_key\":\"535939a7a3bf\",\"_type\":\"block\",\"children\":[{\"_key\":\"553ccc94f3de\",\"_type\":\"span\",\"marks\":[],\"text\":\"For an AI model to be useful in specific contexts, it often needs access to background knowledge. For example, customer support chatbots need knowledge about the specific business they're being used for, and legal analyst bots need to know about a vast array of past cases.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"033f23ed6f56\",\"_type\":\"block\",\"children\":[{\"_key\":\"ecabec661bc3\",\"_type\":\"span\",\"marks\":[],\"text\":\"Developers typically enhance an AI model's knowledge using Retrieval-Augmented Generation (RAG). RAG is a method that retrieves relevant information from a knowledge base and appends it to the user's prompt, significantly enhancing the model's response. The problem is that traditional RAG solutions remove context when encoding information, which often results in the system failing to retrieve the relevant information from the knowledge base.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"0e9531890787\",\"_type\":\"block\",\"children\":[{\"_key\":\"99bf4369e78c\",\"_type\":\"span\",\"marks\":[],\"text\":\"In this post, we outline a method that dramatically improves the retrieval step in RAG. The method is called “Contextual Retrieval” and uses two sub-techniques: Contextual Embeddings and Contextual BM25. This method can reduce the number of failed retrievals by 49% and, when combined with reranking, by 67%. These represent significant improvements in retrieval accuracy, which directly translates to better performance in downstream tasks. \"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"68bfab58f910\",\"_type\":\"block\",\"children\":[{\"_key\":\"4439ba226058\",\"_type\":\"span\",\"marks\":[],\"text\":\"You can easily deploy your own Contextual Retrieval solution with Claude with \"},{\"_key\":\"a20d4436d0db\",\"_type\":\"span\",\"marks\":[\"b75029c31dcc\"],\"text\":\"our cookbook\"},{\"_key\":\"19dec221b2b3\",\"_type\":\"span\",\"marks\":[],\"text\":\".\"}],\"markDefs\":[{\"_key\":\"b75029c31dcc\",\"_type\":\"link\",\"blank\":true,\"href\":\"https://platform.claude.com/cookbook/capabilities-contextual-embeddings-guide\"}],\"style\":\"normal\"},{\"_key\":\"3aa4141a1acd\",\"_type\":\"block\",\"children\":[{\"_key\":\"899fb5689e27\",\"_type\":\"span\",\"marks\":[],\"text\":\"A note on simply using a longer prompt\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"7dd48d031631\",\"_type\":\"block\",\"children\":[{\"_key\":\"0d8551e749b5\",\"_type\":\"span\",\"marks\":[],\"text\":\"Sometimes the simplest solution is the best. If your knowledge base is smaller than 200,000 tokens (about 500 pages of material), you can just include the entire knowledge base in the prompt that you give the model, with no need for RAG or similar methods.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"25e353168bfa\",\"_type\":\"block\",\"children\":[{\"_key\":\"c1c0a62f192c\",\"_type\":\"span\",\"marks\":[],\"text\":\"A few weeks ago, we released \"},{\"_key\":\"abe431f21c59\",\"_type\":\"span\",\"marks\":[\"ce1d90d724ed\"],\"text\":\"prompt caching\"},{\"_key\":\"a62579e13030\",\"_type\":\"span\",\"marks\":[],\"text\":\" for Claude, which makes this approach significantly faster and more cost-effective. Developers can now cache frequently used prompts between API calls, reducing latency by \u003e 2x and costs by up to 90% (you can see how it works by reading our \"},{\"_key\":\"ddc5dda89ac6\",\"_type\":\"span\",\"marks\":[\"cd05520d1a79\"],\"text\":\"prompt caching cookbook\"},{\"_key\":\"b84c75690ae8\",\"_type\":\"span\",\"marks\":[],\"text\":\").\"}],\"markDefs\":[{\"_key\":\"ce1d90d724ed\",\"_type\":\"link\",\"href\":\"https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching\"},{\"_key\":\"cd05520d1a79\",\"_type\":\"link\",\"blank\":true,\"href\":\"https://platform.claude.com/cookbook/misc-prompt-caching\"}],\"style\":\"normal\"},{\"_key\":\"a7bb6347d729\",\"_type\":\"block\",\"children\":[{\"_key\":\"8c892bc1c431\",\"_type\":\"span\",\"marks\":[],\"text\":\"However, as your knowledge base grows, you'll need a more scalable solution. That’s where Contextual Retrieval comes in.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6a31a3dd36f3\",\"_type\":\"block\",\"children\":[{\"_key\":\"cd6394bc2670\",\"_type\":\"span\",\"marks\":[],\"text\":\"A primer on RAG: scaling to larger knowledge bases\"}],\"markDefs\":[],\"style\":\"h2\"},{\"_key\":\"5217eb3bcc36\",\"_type\":\"block\",\"children\":[{\"_key\":\"6648ee23b78c\",\"_type\":\"span\",\"marks\":[],\"text\":\"For larger knowledge bases that don't fit within the context window, RAG is the typical solution. RAG works by preprocessing a knowledge base using the following steps:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"0bd3de161e97\",\"_type\":\"block\",\"children\":[{\"_key\":\"2f3d3ab63afb\",\"_type\":\"span\",\"marks\":[],\"text\":\"Break down the knowledge base (the “corpus” of documents) into smaller chunks of text, usually no more than a few hundred tokens;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"af4598bfeef9\",\"_type\":\"block\",\"children\":[{\"_key\":\"bfde83dd61d1\",\"_type\":\"span\",\"marks\":[],\"text\":\"Use an embedding model to convert these chunks into vector embeddings that encode meaning;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"3cbaa23ca322\",\"_type\":\"block\",\"children\":[{\"_key\":\"94c792f04c46\",\"_type\":\"span\",\"marks\":[],\"text\":\"Store these embeddings in a vector database that allows for searching by semantic similarity.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"157503b957c7\",\"_type\":\"block\",\"children\":[{\"_key\":\"e9b7e6ee33a5\",\"_type\":\"span\",\"marks\":[],\"text\":\"At runtime, when a user inputs a query to the model, the vector database is used to find the most relevant chunks based on semantic similarity to the query. Then, the most relevant chunks are added to the prompt sent to the generative model.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6640c65376c4\",\"_type\":\"block\",\"children\":[{\"_key\":\"2ffcbf386f5a\",\"_type\":\"span\",\"marks\":[],\"text\":\"While embedding models excel at capturing semantic relationships, they can miss crucial exact matches. Fortunately, there’s an older technique that can assist in these situations. BM25 (Best Matching 25) is a ranking function that uses lexical matching to find precise word or phrase matches. It's particularly effective for queries that include unique identifiers or technical terms.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"fb9c452e393b\",\"_type\":\"block\",\"children\":[{\"_key\":\"caf6d638da35\",\"_type\":\"span\",\"marks\":[],\"text\":\"BM25 works by building upon the TF-IDF (Term Frequency-Inverse Document Frequency) concept. TF-IDF measures how important a word is to a document in a collection. BM25 refines this by considering document length and applying a saturation function to term frequency, which helps prevent common words from dominating the results.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6317ac35f04d\",\"_type\":\"block\",\"children\":[{\"_key\":\"f6b3b83f1e14\",\"_type\":\"span\",\"marks\":[],\"text\":\"Here’s how BM25 can succeed where semantic embeddings fail: Suppose a user queries \\\"Error code TS-999\\\" in a technical support database. An embedding model might find content about error codes in general, but could miss the exact \\\"TS-999\\\" match. BM25 looks for this specific text string to identify the relevant documentation.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"f7b9c3a9ddf3\",\"_type\":\"block\",\"children\":[{\"_key\":\"7e9fe209e2bb\",\"_type\":\"span\",\"marks\":[],\"text\":\"RAG solutions can more accurately retrieve the most applicable chunks by combining the embeddings and BM25 techniques using the following steps:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"11cea9b79b42\",\"_type\":\"block\",\"children\":[{\"_key\":\"a0055b42ebde\",\"_type\":\"span\",\"marks\":[],\"text\":\"Break down the knowledge base (the \\\"corpus\\\" of documents) into smaller chunks of text, usually no more than a few hundred tokens;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"82bc03a2b81d\",\"_type\":\"block\",\"children\":[{\"_key\":\"e5cfbe22377a\",\"_type\":\"span\",\"marks\":[],\"text\":\"Create TF-IDF encodings and semantic embeddings for these chunks;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"b9447247a52d\",\"_type\":\"block\",\"children\":[{\"_key\":\"cf8c214879ad\",\"_type\":\"span\",\"marks\":[],\"text\":\"Use BM25 to find top chunks based on exact matches;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"8384dd5d69cf\",\"_type\":\"block\",\"children\":[{\"_key\":\"95ee2e6c2945\",\"_type\":\"span\",\"marks\":[],\"text\":\"Use embeddings to find top chunks based on semantic similarity;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"ddbf7381bacb\",\"_type\":\"block\",\"children\":[{\"_key\":\"36cd6e4293d2\",\"_type\":\"span\",\"marks\":[],\"text\":\"Combine and deduplicate results from (3) and (4) using rank fusion techniques;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"e1071662c8a0\",\"_type\":\"block\",\"children\":[{\"_key\":\"199b2344dd81\",\"_type\":\"span\",\"marks\":[],\"text\":\"Add the top-K chunks to the prompt to generate the response.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"e3e7f0cfb3e4\",\"_type\":\"block\",\"children\":[{\"_key\":\"fc96edf22648\",\"_type\":\"span\",\"marks\":[],\"text\":\"By leveraging both BM25 and embedding models, traditional RAG systems can provide more comprehensive and accurate results, balancing precise term matching with broader semantic understanding.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"63054e463d6d\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-45603646e979c62349ce27744a940abf30200d57-3840x2160-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"7bf052767c5e\",\"_type\":\"block\",\"children\":[{\"_key\":\"f41fd1e805c90\",\"_type\":\"span\",\"marks\":[],\"text\":\"A Standard Retrieval-Augmented Generation (RAG) system that uses both embeddings and Best Match 25 (BM25) to retrieve information. TF-IDF (term frequency-inverse document frequency) measures word importance and forms the basis for BM25.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":2160,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/45603646e979c62349ce27744a940abf30200d57-3840x2160.png\",\"width\":3840},{\"_key\":\"7bb9c56fe201\",\"_type\":\"block\",\"children\":[{\"_key\":\"778fecf75be1\",\"_type\":\"span\",\"marks\":[],\"text\":\"This approach allows you to cost-effectively scale to enormous knowledge bases, far beyond what could fit in a single prompt. But these traditional RAG systems have a significant limitation: they often destroy context.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"371411d5c127\",\"_type\":\"block\",\"children\":[{\"_key\":\"22838ff82920\",\"_type\":\"span\",\"marks\":[],\"text\":\"The context conundrum in traditional RAG\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"1e8fcf09b591\",\"_type\":\"block\",\"children\":[{\"_key\":\"633311df6b3a\",\"_type\":\"span\",\"marks\":[],\"text\":\"In traditional RAG, documents are typically split into smaller chunks for efficient retrieval. While this approach works well for many applications, it can lead to problems when individual chunks lack sufficient context.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"df1cc664011a\",\"_type\":\"block\",\"children\":[{\"_key\":\"02c7cad4eb0a\",\"_type\":\"span\",\"marks\":[],\"text\":\"For example, imagine you had a collection of financial information (say, U.S. SEC filings) embedded in your knowledge base, and you received the following question: \"},{\"_key\":\"1c948a2faafe\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"\\\"What was the revenue growth for ACME Corp in Q2 2023?\\\"\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"0c8b266b8b85\",\"_type\":\"block\",\"children\":[{\"_key\":\"78c93816a213\",\"_type\":\"span\",\"marks\":[],\"text\":\"A relevant chunk might contain the text: \"},{\"_key\":\"f57f6694dc3d\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"\\\"The company's revenue grew by 3% over the previous quarter.\\\"\"},{\"_key\":\"44567d31b52a\",\"_type\":\"span\",\"marks\":[],\"text\":\" However, this chunk on its own doesn't specify which company it's referring to or the relevant time period, making it difficult to retrieve the right information or use the information effectively.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6d5f79129e09\",\"_type\":\"block\",\"children\":[{\"_key\":\"cdbe6e794f04\",\"_type\":\"span\",\"marks\":[],\"text\":\"Introducing Contextual Retrieval\"}],\"markDefs\":[],\"style\":\"h2\"},{\"_key\":\"19d0e24b7836\",\"_type\":\"block\",\"children\":[{\"_key\":\"740ebf410e80\",\"_type\":\"span\",\"marks\":[],\"text\":\"Contextual Retrieval solves this problem by prepending chunk-specific explanatory context to each chunk before embedding (“Contextual Embeddings”) and creating the BM25 index (“Contextual BM25”).\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"66cf114cdaaf\",\"_type\":\"block\",\"children\":[{\"_key\":\"a1174f5c0968\",\"_type\":\"span\",\"marks\":[],\"text\":\"Let’s return to our SEC filings collection example. Here's an example of how a chunk might be transformed:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"2993437a27c2\",\"_type\":\"codeBlock\",\"code\":\"original_chunk = \\\"The company's revenue grew by 3% over the previous quarter.\\\"\\n\\ncontextualized_chunk = \\\"This chunk is from an SEC filing on ACME corp's performance in Q2 2023; the previous quarter's revenue was $314 million. The company's revenue grew by 3% over the previous quarter.\\\"\",\"language\":\"plaintext\",\"markDefs\":null},{\"_key\":\"754367f80f8b\",\"_type\":\"block\",\"children\":[{\"_key\":\"d7f06548a794\",\"_type\":\"span\",\"marks\":[],\"text\":\"It is worth noting that other approaches to using context to improve retrieval have been proposed in the past. Other proposals include: \"},{\"_key\":\"dfbc5f16903d\",\"_type\":\"span\",\"marks\":[\"cb3904942d4f\"],\"text\":\"adding generic document summaries to chunks\"},{\"_key\":\"7f29b0fe2cd4\",\"_type\":\"span\",\"marks\":[],\"text\":\" (we experimented and saw very limited gains), \"},{\"_key\":\"e839bff76404\",\"_type\":\"span\",\"marks\":[\"aab2d1640741\"],\"text\":\"hypothetical document embedding\"},{\"_key\":\"55574afab22f\",\"_type\":\"span\",\"marks\":[],\"text\":\", and \"},{\"_key\":\"4e01a0ecd4da\",\"_type\":\"span\",\"marks\":[\"8423c35f9938\"],\"text\":\"summary-based indexing\"},{\"_key\":\"0f010782892f\",\"_type\":\"span\",\"marks\":[],\"text\":\" (we evaluated and saw low performance). These methods differ from what is proposed in this post.\"}],\"markDefs\":[{\"_key\":\"cb3904942d4f\",\"_type\":\"link\",\"href\":\"https://aclanthology.org/W02-0405.pdf\"},{\"_key\":\"aab2d1640741\",\"_type\":\"link\",\"href\":\"https://arxiv.org/abs/2212.10496\"},{\"_key\":\"8423c35f9938\",\"_type\":\"link\",\"href\":\"https://www.llamaindex.ai/blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec\"}],\"style\":\"normal\"},{\"_key\":\"9b3404fbe484\",\"_type\":\"block\",\"children\":[{\"_key\":\"15d822cf2a4d\",\"_type\":\"span\",\"marks\":[],\"text\":\"Implementing Contextual Retrieval\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"8e79216ecf89\",\"_type\":\"block\",\"children\":[{\"_key\":\"fe0f5a59f86a\",\"_type\":\"span\",\"marks\":[],\"text\":\"Of course, it would be far too much work to manually annotate the thousands or even millions of chunks in a knowledge base. To implement Contextual Retrieval, we turn to Claude. We’ve written a prompt that instructs the model to provide concise, chunk-specific context that explains the chunk using the context of the overall document. We used the following Claude 3 Haiku prompt to generate context for each chunk:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"8d09115f3b07\",\"_type\":\"codeBlock\",\"code\":\"\u003cdocument\u003e \\n{{WHOLE_DOCUMENT}} \\n\u003c/document\u003e \\nHere is the chunk we want to situate within the whole document \\n\u003cchunk\u003e \\n{{CHUNK_CONTENT}} \\n\u003c/chunk\u003e \\nPlease give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else. \",\"language\":\"plaintext\",\"markDefs\":null},{\"_key\":\"f1fc1fd3fe95\",\"_type\":\"block\",\"children\":[{\"_key\":\"a45743062837\",\"_type\":\"span\",\"marks\":[],\"text\":\"The resulting contextual text, usually 50-100 tokens, is prepended to the chunk before embedding it and before creating the BM25 index.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"d1077135a703\",\"_type\":\"block\",\"children\":[{\"_key\":\"2b348f924511\",\"_type\":\"span\",\"marks\":[],\"text\":\"Here’s what the preprocessing flow looks like in practice:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9fbfe73dc1f7\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-2496e7c6fedd7ffaa043895c23a4089638b0c21b-3840x2160-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"c80a55b354f4\",\"_type\":\"block\",\"children\":[{\"_key\":\"91e5901905020\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"Contextual Retrieval is a preprocessing technique that improves retrieval accuracy.\"},{\"_key\":\"960aa659ddce0\",\"_type\":\"span\",\"marks\":[],\"text\":\"\\n\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":2160,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/2496e7c6fedd7ffaa043895c23a4089638b0c21b-3840x2160.png\",\"width\":3840},{\"_key\":\"e76ac0c21f05\",\"_type\":\"block\",\"children\":[{\"_key\":\"57eeadf5ebc8\",\"_type\":\"span\",\"marks\":[],\"text\":\"If you’re interested in using Contextual Retrieval, you can get started with \"},{\"_key\":\"8f2c79616294\",\"_type\":\"span\",\"marks\":[\"5d96912ade7a\"],\"text\":\"our cookbook\"},{\"_key\":\"82d4b62db16f\",\"_type\":\"span\",\"marks\":[],\"text\":\".\"}],\"markDefs\":[{\"_key\":\"5d96912ade7a\",\"_type\":\"link\",\"blank\":true,\"href\":\"https://platform.claude.com/cookbook/capabilities-contextual-embeddings-guide\"}],\"style\":\"normal\"},{\"_key\":\"cf41602a7ef2\",\"_type\":\"block\",\"children\":[{\"_key\":\"7a7a2215eaeb\",\"_type\":\"span\",\"marks\":[],\"text\":\"Using Prompt Caching to reduce the costs of Contextual Retrieval\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"787c02812fe3\",\"_type\":\"block\",\"children\":[{\"_key\":\"21f066dbeece\",\"_type\":\"span\",\"marks\":[],\"text\":\"Contextual Retrieval is uniquely possible at low cost with Claude, thanks to the special prompt caching feature we mentioned above. With prompt caching, you don’t need to pass in the reference document for every chunk. You simply load the document into the cache once and then reference the previously cached content. Assuming 800 token chunks, 8k token documents, 50 token context instructions, and 100 tokens of context per chunk, \"},{\"_key\":\"72abef28ed6c\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"the one-time cost to generate contextualized chunks is $1.02 per million document tokens\"},{\"_key\":\"f038d906137c\",\"_type\":\"span\",\"marks\":[],\"text\":\".\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"81e81a7499eb\",\"_type\":\"block\",\"children\":[{\"_key\":\"808ca7025aa9\",\"_type\":\"span\",\"marks\":[],\"text\":\"Methodology\"}],\"markDefs\":[],\"style\":\"h4\"},{\"_key\":\"2781f4a663b9\",\"_type\":\"block\",\"children\":[{\"_key\":\"2fac56338a64\",\"_type\":\"span\",\"marks\":[],\"text\":\"We experimented across various knowledge domains (codebases, fiction, ArXiv papers, Science Papers), embedding models, retrieval strategies, and evaluation metrics. We’ve included a few examples of the questions and answers we used for each domain in \"},{\"_key\":\"7dd69cd9498a\",\"_type\":\"span\",\"marks\":[\"eef112ee833f\"],\"text\":\"Appendix II\"},{\"_key\":\"a3ebea4f09d1\",\"_type\":\"span\",\"marks\":[],\"text\":\".\"}],\"markDefs\":[{\"_key\":\"eef112ee833f\",\"_type\":\"link\",\"href\":\"https://assets.anthropic.com/m/1632cded0a125333/original/Contextual-Retrieval-Appendix-2.pdf\"}],\"style\":\"normal\"},{\"_key\":\"6aa2fccab059\",\"_type\":\"block\",\"children\":[{\"_key\":\"f7bc877c70b0\",\"_type\":\"span\",\"marks\":[],\"text\":\"The graphs below show the average performance across all knowledge domains with the top-performing embedding configuration (Gemini Text 004) and retrieving the top-20-chunks. We use 1 minus recall@20 as our evaluation metric, which measures the percentage of relevant documents that fail to be retrieved within the top 20 chunks. You can see the full results in the appendix - contextualizing improves performance in every embedding-source combination we evaluated.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"14bedd76863c\",\"_type\":\"block\",\"children\":[{\"_key\":\"86a622c48d41\",\"_type\":\"span\",\"marks\":[],\"text\":\"Performance improvements\"}],\"markDefs\":[],\"style\":\"h4\"},{\"_key\":\"314bca5524e8\",\"_type\":\"block\",\"children\":[{\"_key\":\"cd5b01355cc1\",\"_type\":\"span\",\"marks\":[],\"text\":\"Our experiments showed that:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9f3a7623176b\",\"_type\":\"block\",\"children\":[{\"_key\":\"38fafb41c0cf\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Contextual Embeddings reduced the top-20-chunk retrieval failure rate by 35%\"},{\"_key\":\"0a20ed108871\",\"_type\":\"span\",\"marks\":[],\"text\":\" (5.7% → 3.7%).\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"1c21f8982a18\",\"_type\":\"block\",\"children\":[{\"_key\":\"74b31ecb7e22\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Combining Contextual Embeddings and Contextual BM25 reduced the top-20-chunk retrieval failure rate by 49%\"},{\"_key\":\"1e2d83fde93a\",\"_type\":\"span\",\"marks\":[],\"text\":\" (5.7% → 2.9%).\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9020e7847a37\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-7f8d739e491fe6b3ba0e6a9c74e4083d760b88c9-3840x2160-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"4cb730205ea5\",\"_type\":\"block\",\"children\":[{\"_key\":\"252156f725c90\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"Combining Contextual Embedding and Contextual BM25 reduce the top-20-chunk retrieval failure rate by 49%.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":2160,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/7f8d739e491fe6b3ba0e6a9c74e4083d760b88c9-3840x2160.png\",\"width\":3840},{\"_key\":\"3e54d8f1bc3c\",\"_type\":\"block\",\"children\":[{\"_key\":\"3fca038cb097\",\"_type\":\"span\",\"marks\":[],\"text\":\"Implementation considerations\"}],\"markDefs\":[],\"style\":\"h4\"},{\"_key\":\"28b2f4c3a764\",\"_type\":\"block\",\"children\":[{\"_key\":\"3e8bd18a5f2e\",\"_type\":\"span\",\"marks\":[],\"text\":\"When implementing Contextual Retrieval, there are a few considerations to keep in mind:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"f5d6bccbb749\",\"_type\":\"block\",\"children\":[{\"_key\":\"2e920485b370\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Chunk boundaries:\"},{\"_key\":\"c495d881e025\",\"_type\":\"span\",\"marks\":[],\"text\":\" Consider how you split your documents into chunks. The choice of chunk size, chunk boundary, and chunk overlap can affect retrieval performance\"},{\"_key\":\"1732f639e580\",\"_type\":\"span\",\"marks\":[\"sup\"],\"text\":\"1\"},{\"_key\":\"7f6f32f81645\",\"_type\":\"span\",\"marks\":[],\"text\":\".\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"4438f4c3cece\",\"_type\":\"block\",\"children\":[{\"_key\":\"8fad00faa817\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Embedding model:\"},{\"_key\":\"11f98207d9d3\",\"_type\":\"span\",\"marks\":[],\"text\":\" Whereas Contextual Retrieval improves performance across all embedding models we tested, some models may benefit more than others. We found \"},{\"_key\":\"1d6a6aa1f8b8\",\"_type\":\"span\",\"marks\":[\"1a27059bb4c9\"],\"text\":\"Gemini\"},{\"_key\":\"d1bbc59ca527\",\"_type\":\"span\",\"marks\":[],\"text\":\" and \"},{\"_key\":\"9ed076913563\",\"_type\":\"span\",\"marks\":[\"6f21ea387254\"],\"text\":\"Voyage\"},{\"_key\":\"117b58e55ecc\",\"_type\":\"span\",\"marks\":[],\"text\":\" embeddings to be particularly effective.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[{\"_key\":\"1a27059bb4c9\",\"_type\":\"link\",\"href\":\"https://ai.google.dev/gemini-api/docs/embeddings\"},{\"_key\":\"6f21ea387254\",\"_type\":\"link\",\"href\":\"https://www.voyageai.com/\"}],\"style\":\"normal\"},{\"_key\":\"4763b4fdcd09\",\"_type\":\"block\",\"children\":[{\"_key\":\"5925a8ab92f6\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Custom contextualizer prompts:\"},{\"_key\":\"fb66f4761d61\",\"_type\":\"span\",\"marks\":[],\"text\":\" While the generic prompt we provided works well, you may be able to achieve even better results with prompts tailored to your specific domain or use case (for example, including a glossary of key terms that might only be defined in other documents in the knowledge base).\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6b41e361b2c7\",\"_type\":\"block\",\"children\":[{\"_key\":\"683e1bb225c6\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Number of chunks:\"},{\"_key\":\"871631b1c8e3\",\"_type\":\"span\",\"marks\":[],\"text\":\" Adding more chunks into the context window increases the chances that you include the relevant information. However, more information can be distracting for models so there's a limit to this. We tried delivering 5, 10, and 20 chunks, and found using 20 to be the most performant of these options (see appendix for comparisons) but it’s worth experimenting on your use case.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"a40fdb8f1d02\",\"_type\":\"block\",\"children\":[{\"_key\":\"9905da02eaff\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Always run evals: \"},{\"_key\":\"4323a799d3ca\",\"_type\":\"span\",\"marks\":[],\"text\":\"Response generation may be improved by passing it the contextualized chunk and distinguishing between what is context and what is the chunk.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"d84401e8566c\",\"_type\":\"block\",\"children\":[{\"_key\":\"039494d4ae10\",\"_type\":\"span\",\"marks\":[],\"text\":\"Further boosting performance with Reranking\"}],\"markDefs\":[],\"style\":\"h2\"},{\"_key\":\"707a1db85f3f\",\"_type\":\"block\",\"children\":[{\"_key\":\"ff28ab8e58e1\",\"_type\":\"span\",\"marks\":[],\"text\":\"In a final step, we can combine Contextual Retrieval with another technique to give even more performance improvements. In traditional RAG, the AI system searches its knowledge base to find the potentially relevant information chunks. With large knowledge bases, this initial retrieval often returns a lot of chunks—sometimes hundreds—of varying relevance and importance.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6c0f16b34b5b\",\"_type\":\"block\",\"children\":[{\"_key\":\"29020d923233\",\"_type\":\"span\",\"marks\":[],\"text\":\"Reranking is a commonly used filtering technique to ensure that only the most relevant chunks are passed to the model. Reranking provides better responses and reduces cost and latency because the model is processing less information. The key steps are:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"d78d998b28ec\",\"_type\":\"block\",\"children\":[{\"_key\":\"875e19b68f67\",\"_type\":\"span\",\"marks\":[],\"text\":\"Perform initial retrieval to get the top potentially relevant chunks (we used the top 150);\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"c88a7779ff22\",\"_type\":\"block\",\"children\":[{\"_key\":\"f1ae27626580\",\"_type\":\"span\",\"marks\":[],\"text\":\"Pass the top-N chunks, along with the user's query, through the reranking model;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"a89b4b768e14\",\"_type\":\"block\",\"children\":[{\"_key\":\"695679385618\",\"_type\":\"span\",\"marks\":[],\"text\":\"Using a reranking model, give each chunk a score based on its relevance and importance to the prompt, then select the top-K chunks (we used the top 20);\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"c5095277304e\",\"_type\":\"block\",\"children\":[{\"_key\":\"d576a395fd22\",\"_type\":\"span\",\"marks\":[],\"text\":\"Pass the top-K chunks into the model as context to generate the final result.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"03f4f495f2bf\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-8f82c6175a64442ceff4334b54fac2ab3436a1d1-3840x2160-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"f937f2e59c9e\",\"_type\":\"block\",\"children\":[{\"_key\":\"5fb61e05d3580\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"Combine Contextual Retrieva and Reranking to maximize retrieval accuracy.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":2160,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/8f82c6175a64442ceff4334b54fac2ab3436a1d1-3840x2160.png\",\"width\":3840},{\"_key\":\"d7f9e1e05451\",\"_type\":\"block\",\"children\":[{\"_key\":\"5343d64b4a44\",\"_type\":\"span\",\"marks\":[],\"text\":\"Performance improvements\"}],\"markDefs\":[],\"style\":\"h3\"},{\"_key\":\"04c1095c201c\",\"_type\":\"block\",\"children\":[{\"_key\":\"f4fe0bb23e4d\",\"_type\":\"span\",\"marks\":[],\"text\":\"There are several reranking models on the market. We ran our tests with the \"},{\"_key\":\"4e9cb7f28c1b\",\"_type\":\"span\",\"marks\":[\"e6cd63ff04f9\"],\"text\":\"Cohere reranker\"},{\"_key\":\"ba6bd0cde8f6\",\"_type\":\"span\",\"marks\":[],\"text\":\". Voyage\"},{\"_key\":\"51b6500e0cfb\",\"_type\":\"span\",\"marks\":[\"05019761e34b\"],\"text\":\" also offers a reranker\"},{\"_key\":\"c50b009dbc42\",\"_type\":\"span\",\"marks\":[],\"text\":\", though we did not have time to test it. Our experiments showed that, across various domains, adding a reranking step further optimizes retrieval.\"}],\"markDefs\":[{\"_key\":\"e6cd63ff04f9\",\"_type\":\"link\",\"href\":\"https://cohere.com/rerank\"},{\"_key\":\"05019761e34b\",\"_type\":\"link\",\"href\":\"https://docs.voyageai.com/docs/reranker\"}],\"style\":\"normal\"},{\"_key\":\"10033f7ee185\",\"_type\":\"block\",\"children\":[{\"_key\":\"1990363deb47\",\"_type\":\"span\",\"marks\":[],\"text\":\"Specifically, we found that Reranked Contextual Embedding and Contextual BM25 reduced the top-20-chunk retrieval failure rate by 67% (5.7% → 1.9%).\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"555635a94abb\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-93a70cfbb7cca35bb8d86ea0a23bdeeb699e8e58-3840x2160-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"bbae64fb6b26\",\"_type\":\"block\",\"children\":[{\"_key\":\"123abccf2b5d0\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"Reranked Contextual Embedding and Contextual BM25 reduces the top-20-chunk retrieval failure rate by 67%.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":2160,\"markDefs\":null,\"style\":\"inline\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/93a70cfbb7cca35bb8d86ea0a23bdeeb699e8e58-3840x2160.png\",\"width\":3840},{\"_key\":\"fedc8c4c589c\",\"_type\":\"block\",\"children\":[{\"_key\":\"980799ac5d42\",\"_type\":\"span\",\"marks\":[],\"text\":\"Cost and latency considerations\"}],\"markDefs\":[],\"style\":\"h4\"},{\"_key\":\"3b91dfcd4ba6\",\"_type\":\"block\",\"children\":[{\"_key\":\"889791479416\",\"_type\":\"span\",\"marks\":[],\"text\":\"One important consideration with reranking is the impact on latency and cost, especially when reranking a large number of chunks. Because reranking adds an extra step at runtime, it inevitably adds a small amount of latency, even though the reranker scores all the chunks in parallel. There is an inherent trade-off between reranking more chunks for better performance vs. reranking fewer for lower latency and cost. We recommend experimenting with different settings on your specific use case to find the right balance.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"a76669af7b54\",\"_type\":\"block\",\"children\":[{\"_key\":\"0f68a6023a2c\",\"_type\":\"span\",\"marks\":[],\"text\":\"Conclusion\"}],\"markDefs\":[],\"style\":\"h2\"},{\"_key\":\"7728980175ef\",\"_type\":\"block\",\"children\":[{\"_key\":\"bfb83de2d493\",\"_type\":\"span\",\"marks\":[],\"text\":\"We ran a large number of tests, comparing different combinations of all the techniques described above (embedding model, use of BM25, use of contextual retrieval, use of a reranker, and total # of top-K results retrieved), all across a variety of different dataset types. Here’s a summary of what we found:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"f091941c2c6d\",\"_type\":\"block\",\"children\":[{\"_key\":\"0fd97b1fb0b9\",\"_type\":\"span\",\"marks\":[],\"text\":\"Embeddings+BM25 is better than embeddings on their own;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"b3e253f5e840\",\"_type\":\"block\",\"children\":[{\"_key\":\"5b079df8ac61\",\"_type\":\"span\",\"marks\":[],\"text\":\"Voyage and Gemini have the best embeddings of the ones we tested;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"d43f7fbd780a\",\"_type\":\"block\",\"children\":[{\"_key\":\"760f02fdd4eb\",\"_type\":\"span\",\"marks\":[],\"text\":\"Passing the top-20 chunks to the model is more effective than just the top-10 or top-5;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"02d406345e70\",\"_type\":\"block\",\"children\":[{\"_key\":\"17961d7be3ae\",\"_type\":\"span\",\"marks\":[],\"text\":\"Adding context to chunks improves retrieval accuracy a lot;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"1ec14aa5dbb1\",\"_type\":\"block\",\"children\":[{\"_key\":\"4652eaf1c347\",\"_type\":\"span\",\"marks\":[],\"text\":\"Reranking is better than no reranking;\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"2cf7a033dd7b\",\"_type\":\"block\",\"children\":[{\"_key\":\"65114336c2ae\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"All these benefits stack\"},{\"_key\":\"f9761ff101a4\",\"_type\":\"span\",\"marks\":[],\"text\":\": to maximize performance improvements, we can combine contextual embeddings (from Voyage or Gemini) with contextual BM25, plus a reranking step, and adding the 20 chunks to the prompt.\"}],\"level\":1,\"listItem\":\"number\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9255560ebf7c\",\"_type\":\"block\",\"children\":[{\"_key\":\"0a04687bbd72\",\"_type\":\"span\",\"marks\":[],\"text\":\"We encourage all developers working with knowledge bases to use \"},{\"_key\":\"b571582f166c\",\"_type\":\"span\",\"marks\":[\"1f4788f4cc2d\"],\"text\":\"our cookbook\"},{\"_key\":\"e6cb479f46bd\",\"_type\":\"span\",\"marks\":[],\"text\":\" to experiment with these approaches to unlock new levels of performance.\"}],\"markDefs\":[{\"_key\":\"1f4788f4cc2d\",\"_type\":\"link\",\"blank\":true,\"href\":\"https://platform.claude.com/cookbook/capabilities-contextual-embeddings-guide\"}],\"style\":\"normal\"},{\"_key\":\"aa465fd20e7a\",\"_type\":\"block\",\"children\":[{\"_key\":\"3db239761d9c\",\"_type\":\"span\",\"marks\":[],\"text\":\"Appendix I\"}],\"markDefs\":[],\"style\":\"h2\"},{\"_key\":\"ee53e26a14d8\",\"_type\":\"block\",\"children\":[{\"_key\":\"87a9ab1a3b0d\",\"_type\":\"span\",\"marks\":[],\"text\":\"Below is a breakdown of results across datasets, embedding providers, use of BM25 in addition to embeddings, use of contextual retrieval, and use of reranking for Retrievals @ 20.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"cc56c4ec6f2b\",\"_type\":\"block\",\"children\":[{\"_key\":\"f55c5bd1276a\",\"_type\":\"span\",\"marks\":[],\"text\":\"See \"},{\"_key\":\"f6dcfa6f71d1\",\"_type\":\"span\",\"marks\":[\"87d47ba47a6c\"],\"text\":\"Appendix II\"},{\"_key\":\"dbfb4336332a\",\"_type\":\"span\",\"marks\":[],\"text\":\" for the breakdowns for Retrievals @ 10 and @ 5 as well as example questions and answers for each dataset.\"}],\"markDefs\":[{\"_key\":\"87d47ba47a6c\",\"_type\":\"link\",\"href\":\"https://assets.anthropic.com/m/1632cded0a125333/original/Contextual-Retrieval-Appendix-2.pdf\"}],\"style\":\"normal\"},{\"_key\":\"ec1cb9b88cba\",\"_type\":\"image\",\"asset\":{\"_ref\":\"image-646a894ec4e6120cade9951a362f685cd2ec89b2-2458x2983-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"25873311fdeb\",\"_type\":\"block\",\"children\":[{\"_key\":\"4d2e5106e9250\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"1 minus recall @ 20 results across data sets and embedding providers.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"height\":2983,\"markDefs\":null,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/646a894ec4e6120cade9951a362f685cd2ec89b2-2458x2983.png\",\"width\":2458},{\"_key\":\"d5f29e7614f3\",\"_type\":\"block\",\"children\":[{\"_key\":\"66dde349ed7a\",\"_type\":\"span\",\"marks\":[],\"text\":\"\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"0d1f0af5dfad\",\"_type\":\"block\",\"children\":[{\"_key\":\"4545e79c7ade\",\"_type\":\"span\",\"marks\":[],\"text\":\"Acknowledgements \"}],\"markDefs\":[],\"style\":\"h2\"},{\"_key\":\"dec4f1e50209\",\"_type\":\"block\",\"children\":[{\"_key\":\"3ee1f327028d0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Research and writing by Daniel Ford. Thanks to Orowa Sikder, Gautam Mittal, and Kenneth Lien for critical feedback, Samuel Flamini for implementing the cookbooks, Lauren Polansky for project coordination and Alex Albert, Susan Payne, Stuart Ritchie, and Brad Abrams for shaping this blog post.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"cardImage\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-7e2e39544a35760367049072406377a54f2b58c0-2554x2554-svg\",\"_type\":\"reference\"},\"height\":2554,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/7e2e39544a35760367049072406377a54f2b58c0-2554x2554.svg\",\"width\":2554},\"cardPhoto\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-fe3964a523a8f24120868381c873af7dd7b4270c-1000x1000-svg\",\"_type\":\"reference\"}},\"hero\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-7e2e39544a35760367049072406377a54f2b58c0-2554x2554-svg\",\"_type\":\"reference\"},\"caption\":null,\"height\":2554,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/7e2e39544a35760367049072406377a54f2b58c0-2554x2554.svg\",\"width\":2554},\"meta\":{\"robotsIndexable\":true,\"seoDescription\":\"Explore how Anthropic enhances AI systems through advanced contextual retrieval methods. Learn about our approach to improving information access and relevance in large language models.\",\"seoTitle\":\"Contextual Retrieval in AI Systems\",\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_createdAt\":\"2025-03-04T17:31:20Z\",\"_id\":\"image-2bb957622142f53575f476f76473593fa89d1dc8-2400x1260-png\",\"_rev\":\"5iCDfF6Hw611lBP7UO6q4D\",\"_type\":\"sanity.imageAsset\",\"_updatedAt\":\"2025-03-04T17:31:20Z\",\"assetId\":\"2bb957622142f53575f476f76473593fa89d1dc8\",\"extension\":\"png\",\"metadata\":{\"_type\":\"sanity.imageMetadata\",\"blurHash\":\"MGQ,EytR~pxaD%-:j[WBWBj[.7jaD%W;xu\",\"dimensions\":{\"_type\":\"sanity.imageDimensions\",\"aspectRatio\":1.9047619047619047,\"height\":1260,\"width\":2400},\"hasAlpha\":true,\"isOpaque\":true,\"lqip\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABHUlEQVR4nJ2Ty06DYBBG+9wuNHHTx1Bjaq0GrEhCWzBcS0G8lLYCLVpuAtIW0Sf4TFm5Mfp3cTKLmZxMMt80Pj8y/IevKq/5a67xW6MqU2xWCTaruGZdRCjyEEUeoFwn5MIiD+DPJ5hNrJqpbeHB0nBvaYjDObkwDj0YugRFGtSIAgeOodBjaPiuTS6MAheaIkCWBlAVHgrPQaWuYNIMIne624aqzIPv30CW+jBFATbFwqU55J5DLnSfH3HWOkK7dYyRLmJ8N4TeZWDQ14jdGZmwKjOYIxkH+3toNg8hiT1Ypgq2ewmW7mDhjMk39JwnnLdPcNE5xVC7ra+7rYYuIgo8cuE2e2niI4kXdU2TF2Rvr3jPlrvlkOQ7fgq/AQNZHzHOPZgIAAAAAElFTkSuQmCC\",\"palette\":{\"_type\":\"sanity.imagePalette\",\"darkMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#44443d\",\"foreground\":\"#fff\",\"population\":0.12,\"title\":\"#fff\"},\"darkVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#5d2637\",\"foreground\":\"#fff\",\"population\":0,\"title\":\"#fff\"},\"dominant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#bf6581\",\"foreground\":\"#fff\",\"population\":0.7,\"title\":\"#fff\"},\"lightMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#c6a4ac\",\"foreground\":\"#000\",\"population\":0.01,\"title\":\"#fff\"},\"lightVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#db88a0\",\"foreground\":\"#000\",\"population\":0.09,\"title\":\"#fff\"},\"muted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#aa6074\",\"foreground\":\"#fff\",\"population\":0.04,\"title\":\"#fff\"},\"vibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#bf6581\",\"foreground\":\"#fff\",\"population\":0.7,\"title\":\"#fff\"}}},\"mimeType\":\"image/png\",\"originalFilename\":\"eng-blog-social1.png\",\"path\":\"images/4zrzovbb/website/2bb957622142f53575f476f76473593fa89d1dc8-2400x1260.png\",\"sha1hash\":\"2bb957622142f53575f476f76473593fa89d1dc8\",\"size\":73511,\"uploadId\":\"JGYxCKH8n324l7whrIrWosu4iL6WH3rI\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/2bb957622142f53575f476f76473593fa89d1dc8-2400x1260.png\"}}},\"publishedOn\":\"2024-09-19\",\"slug\":{\"_type\":\"slug\",\"current\":\"contextual-retrieval\"},\"spotIllustration\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-44e93e074d53285f64ff717365b04c4a2164a445-1200x1200-svg\",\"_type\":\"reference\"},\"height\":1200,\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/44e93e074d53285f64ff717365b04c4a2164a445-1200x1200.svg\",\"width\":1200},\"subjects\":[{\"_key\":\"performance\",\"_type\":\"tag\",\"label\":\"Performance\",\"value\":\"performance\"}],\"summary\":\"For an AI model to be useful in specific contexts, it often needs access to background knowledge. \",\"title\":\"Introducing Contextual Retrieval\"},\"siteSettings\":{\"_createdAt\":\"2023-11-03T16:49:36Z\",\"_id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"_rev\":\"yTRh7AEP4D5VL0KlacX84u\",\"_system\":{\"base\":{\"id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"rev\":\"l72pC1z2B6rbHkO6aMcVVS\"}},\"_type\":\"siteSettings\",\"_updatedAt\":\"2026-02-10T21:50:58Z\",\"announcement\":null,\"claudeCta\":{\"desktopCtas\":null,\"mobileCtas\":[{\"title\":\"Log in to Claude\",\"url\":\"https://claude.ai/login\"},{\"title\":\"Download app\",\"url\":\"https://claude.ai/download\"}],\"sections\":[{\"category\":\"Products\",\"links\":[{\"title\":\"Claude\",\"url\":\"https://claude.com/product/overview\"},{\"title\":\"Claude Code\",\"url\":\"https://claude.com/product/claude-code\"},{\"title\":\"Claude Developer Platform\",\"url\":\"https://claude.com/platform/api\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing\"},{\"title\":\"Contact sales\",\"url\":\"https://claude.com/contact-sales\"}]},{\"category\":\"Models\",\"links\":[{\"title\":\"Opus\",\"url\":\"/claude/opus\"},{\"title\":\"Sonnet\",\"url\":\"/claude/sonnet\"},{\"title\":\"Haiku\",\"url\":\"/claude/haiku\"}]},{\"category\":\"Log in\",\"links\":[{\"title\":\"Claude.ai\",\"url\":\"https://claude.ai\"},{\"title\":\"Claude Console\",\"url\":\"https://platform.claude.com/\"}]}],\"title\":\"Try Claude\",\"url\":\"https://claude.ai/\"},\"copyright\":\"© 2026 Anthropic PBC\",\"footerNavigation\":[{\"_key\":\"716b96b62292\",\"links\":[{\"title\":\"Claude\",\"url\":\"https://claude.com/product/overview\"},{\"title\":\"Claude Code\",\"url\":\"https://claude.com/product/claude-code\"},{\"title\":\"Cowork\",\"url\":\"https://claude.com/product/cowork\"},{\"title\":\"Claude in Chrome\",\"url\":\"https://claude.com/chrome\"},{\"title\":\"Claude in Excel\",\"url\":\"https://claude.com/claude-in-excel\"},{\"title\":\"Claude in PowerPoint\",\"url\":\"https://claude.com/claude-in-powerpoint\"},{\"title\":\"Claude in Slack\",\"url\":\"https://claude.com/claude-in-slack\"},{\"title\":\"Skills\",\"url\":\"https://www.claude.com/skills\"},{\"title\":\"Max plan\",\"url\":\"https://claude.com/pricing/max\"},{\"title\":\"Team plan\",\"url\":\"https://claude.com/pricing/team\"},{\"title\":\"Enterprise plan\",\"url\":\"https://claude.com/pricing/enterprise\"},{\"title\":\"Download app\",\"url\":\"https://claude.ai/download\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing\"},{\"title\":\"Log in to Claude\",\"url\":\"https://claude.ai/\"}],\"title\":\"Products\"},{\"_key\":\"0229138ff25d\",\"links\":[{\"title\":\"Opus\",\"url\":\"/www.anthropic.com/claude/opus\"},{\"title\":\"Sonnet\",\"url\":\"/www.anthropic.com/claude/sonnet\"},{\"title\":\"Haiku\",\"url\":\"/www.anthropic.com/claude/haiku\"}],\"title\":\"Models\"},{\"_key\":\"df2df9219e3abce95d6d83387e2d9bd6\",\"links\":[{\"title\":\"AI agents\",\"url\":\"https://claude.com/solutions/agents\"},{\"title\":\"Code modernization\",\"url\":\"https://claude.com/solutions/code-modernization\"},{\"title\":\"Coding\",\"url\":\"https://claude.com/solutions/coding\"},{\"title\":\"Customer support\",\"url\":\"https://claude.com/solutions/customer-support\"},{\"title\":\"Education\",\"url\":\"https://claude.com/solutions/education\"},{\"title\":\"Financial services\",\"url\":\"https://claude.com/solutions/financial-services\"},{\"title\":\"Government\",\"url\":\"https://claude.com/solutions/government\"},{\"title\":\"Healthcare\",\"url\":\"https://claude.com/solutions/healthcare\"},{\"title\":\"Life sciences\",\"url\":\"https://claude.com/solutions/life-sciences\"},{\"title\":\"Nonprofits\",\"url\":\"https://claude.com/solutions/nonprofits\"}],\"title\":\"Solutions\"},{\"_key\":\"f286ca01fc7aaabd131f347b711a971b\",\"links\":[{\"title\":\"Overview\",\"url\":\"https://claude.com/platform/api\"},{\"title\":\"Developer docs\",\"url\":\"https://platform.claude.com/docs\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing#api\"},{\"title\":\"Regional compliance\",\"url\":\"https://claude.com/regional-compliance\"},{\"title\":\"Amazon Bedrock\",\"url\":\"https://claude.com/partners/amazon-bedrock\"},{\"title\":\"Google Cloud’s Vertex AI\",\"url\":\"https://claude.com/partners/google-cloud-vertex-ai\"},{\"title\":\"Console login\",\"url\":\"https://platform.claude.com/\"}],\"title\":\"Claude Developer Platform\"},{\"_key\":\"4b255e67f68c270e0072c7564e084e24\",\"links\":[{\"title\":\"Blog\",\"url\":\"https://claude.com/blog\"},{\"title\":\"Claude partner network\",\"url\":\"https://claude.com/partners\"},{\"title\":\"Connectors\",\"url\":\"https://claude.com/connectors\"},{\"title\":\"Courses\",\"url\":\"/learn\"},{\"title\":\"Customer stories\",\"url\":\"https://claude.com/customers\"},{\"title\":\"Engineering at Anthropic\",\"url\":\"/engineering\"},{\"title\":\"Events\",\"url\":\"/events\"},{\"title\":\"Plugins\",\"url\":\"https://claude.com/plugins\"},{\"title\":\"Powered by Claude\",\"url\":\"https://claude.com/partners/powered-by-claude\"},{\"title\":\"Service partners\",\"url\":\"https://claude.com/partners/services\"},{\"title\":\"Startups program\",\"url\":\"https://claude.com/programs/startups\"},{\"title\":\"Tutorials\",\"url\":\"https://claude.com/resources/tutorials\"},{\"title\":\"Use cases\",\"url\":\"https://claude.com/resources/use-cases\"}],\"title\":\"Learn\"},{\"_key\":\"4f2729951e15b0b870897e0444f5f3e1\",\"links\":[{\"title\":\"Anthropic\",\"url\":\"/company\"},{\"title\":\"Careers\",\"url\":\"/careers\"},{\"title\":\"Economic Futures\",\"url\":\"/economic-index\"},{\"title\":\"Research\",\"url\":\"/research\"},{\"title\":\"News\",\"url\":\"/news\"},{\"title\":\"Claude’s Constitution\",\"url\":\"/constitution\"},{\"title\":\"Responsible Scaling Policy\",\"url\":\"/www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy\"},{\"title\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com/\"},{\"title\":\"Transparency\",\"url\":\"/transparency\"}],\"title\":\"Company\"},{\"_key\":\"a886dd1838335844d635f2857b25d66a\",\"links\":[{\"title\":\"Availability\",\"url\":\"/www.anthropic.com/supported-countries\"},{\"title\":\"Status\",\"url\":\"https://status.anthropic.com/\"},{\"title\":\"Support center\",\"url\":\"https://support.claude.com/en/\"}],\"title\":\"Help and security\"},{\"_key\":\"3c3b033c11fa832a35d43b87d55a5364\",\"links\":[{\"title\":\"Privacy choices\",\"url\":\"#\"},{\"title\":\"Privacy policy\",\"url\":\"/www.anthropic.com/legal/privacy\"},{\"title\":\"Consumer health data privacy policy\",\"url\":\"/www.anthropic.com/legal/consumer-health-data-privacy-policy\"},{\"title\":\"Responsible disclosure policy\",\"url\":\"/www.anthropic.com/responsible-disclosure-policy\"},{\"title\":\"Terms of service: Commercial\",\"url\":\"/www.anthropic.com/legal/commercial-terms\"},{\"title\":\"Terms of service: Consumer\",\"url\":\"/www.anthropic.com/legal/consumer-terms\"},{\"title\":\"Usage policy\",\"url\":\"/www.anthropic.com/legal/aup\"}],\"title\":\"Terms and policies\"}],\"headerNavigation\":[{\"_key\":\"a340f9d4b859\",\"category\":\"Research\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/research\"},{\"_key\":\"a483c7dfd38a\",\"category\":\"Economic Futures\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/economic-futures\"},{\"_key\":\"82c471bd311d\",\"category\":\"Commitments\",\"displayType\":\"sections\",\"sections\":[{\"_key\":\"675871636e4d\",\"links\":[{\"title\":\"Claude’s Constitution\",\"url\":\"/constitution\"},{\"title\":\" Transparency\",\"url\":\"/transparency\"},{\"title\":\"Responsible Scaling Policy\",\"url\":\"/news/announcing-our-updated-responsible-scaling-policy\"}],\"title\":\"Initiatives\"},{\"_key\":\"16af50a6e2dd\",\"links\":[{\"title\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com/\"}],\"title\":\"Trust center\"}]},{\"_key\":\"861a11ed9931\",\"category\":\"Learn\",\"displayType\":\"sections\",\"sections\":[{\"_key\":\"9f9f720a8793\",\"links\":[{\"title\":\"Anthropic Academy\",\"url\":\"/learn\"},{\"title\":\"Tutorials\",\"url\":\"https://claude.com/resources/tutorials\"},{\"title\":\"Use cases\",\"url\":\"https://claude.com/resources/use-cases\"},{\"title\":\"Engineering at Anthropic\",\"url\":\"/engineering\"},{\"title\":\"Developer docs\",\"url\":\"https://docs.claude.com\"}],\"title\":\"Learn\"},{\"_key\":\"6bd061c46b10\",\"links\":[{\"title\":\"About\",\"url\":\"/company\"},{\"title\":\"Careers\",\"url\":\"/careers\"},{\"title\":\"Events\",\"url\":\"/events\"}],\"title\":\"Company\"}]},{\"_key\":\"22e8d8d2923d\",\"category\":\"News\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/news\"}],\"internalName\":\"anthropic.com Site Settings\",\"linkedInUsername\":\"anthropicresearch\",\"meta\":{\"_createdAt\":\"2023-11-20T21:56:31Z\",\"_id\":\"0f6290ad-6d21-407d-8deb-ce02815d1383\",\"_rev\":\"NyW74GU9ZzyWgAYa8qUSlF\",\"_type\":\"metadata\",\"_updatedAt\":\"2023-11-20T23:54:09Z\",\"robotsIndexable\":true,\"seoDescription\":\"Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems.\",\"seoTitle\":\"Anthropic\",\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_createdAt\":\"2025-05-23T14:14:18Z\",\"_id\":\"image-c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260-jpg\",\"_rev\":\"v1N2wBpLqoO2Q3HXueYiJi\",\"_type\":\"sanity.imageAsset\",\"_updatedAt\":\"2025-05-23T14:14:18Z\",\"assetId\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"extension\":\"jpg\",\"metadata\":{\"_type\":\"sanity.imageMetadata\",\"blurHash\":\"MASPU,%M?b%Ms:-;j[j[j[fQ~qj[9FayWB\",\"dimensions\":{\"_type\":\"sanity.imageDimensions\",\"aspectRatio\":1.9047619047619047,\"height\":1260,\"width\":2400},\"hasAlpha\":false,\"isOpaque\":true,\"lqip\":\"data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAKABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAQFCP/EACAQAAEEAgEFAAAAAAAAAAAAAAABAgMEBRETEhQhIjH/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwDS96axCjO2r8yqvn21oiR3ci6TT8d0t395ELUGVAAB/9k=\",\"palette\":{\"_type\":\"sanity.imagePalette\",\"darkMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#444440\",\"foreground\":\"#fff\",\"population\":0.05,\"title\":\"#fff\"},\"darkVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#68681c\",\"foreground\":\"#fff\",\"population\":0,\"title\":\"#fff\"},\"dominant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"lightMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#bcbcb4\",\"foreground\":\"#000\",\"population\":0.03,\"title\":\"#fff\"},\"lightVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"muted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#7c7c74\",\"foreground\":\"#fff\",\"population\":0.02,\"title\":\"#fff\"},\"vibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#c8c836\",\"foreground\":\"#000\",\"population\":0,\"title\":\"#fff\"}}},\"mimeType\":\"image/jpeg\",\"originalFilename\":\"Anthropic-OG-image.jpg\",\"path\":\"images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\",\"sha1hash\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"size\":132598,\"uploadId\":\"pxmJEaCvYm0cHoZTfnCcZYXxrWKBhHf0\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\"},\"description\":\"Anthropic logo\"}},\"siteName\":\"Anthropic\",\"sitemapUrls\":[\"/\",\"/careers\",\"/company\",\"/events\",\"/events/aws-summit-dc\",\"/events/aws-summit-nyc\",\"/events/aws-summit-london\",\"/events/aws-summit-tokyo\",\"/events/claude-for-finance\",\"/events/google-cloud-next-2025\",\"/events/paris-builder-summit\",\"/events/seoul-builder-summit\",\"/learn\",\"/supported-countries\",\"/unsubscribe\"],\"twitterUsername\":\"AnthropicAI\",\"youtubeUsername\":\"anthropic-ai\"}}]\n"])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"f:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"2\",{\"name\":\"theme-color\",\"content\":\"#141413\"}]]\n"])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"15:[\"$\",\"$L17\",null,{\"children\":[null,[\"$\",\"$L18\",null,{\"isMinimalNavigation\":\"$undefined\",\"siteSettings\":{\"_createdAt\":\"2023-11-03T16:49:36Z\",\"_id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"_rev\":\"yTRh7AEP4D5VL0KlacX84u\",\"_system\":{\"base\":{\"id\":\"13c6e1a1-6f38-400c-ae18-89d73b6ba991\",\"rev\":\"l72pC1z2B6rbHkO6aMcVVS\"}},\"_type\":\"siteSettings\",\"_updatedAt\":\"2026-02-10T21:50:58Z\",\"announcement\":null,\"claudeCta\":{\"desktopCtas\":null,\"mobileCtas\":[{\"title\":\"Log in to Claude\",\"url\":\"https://claude.ai/login\"},{\"title\":\"Download app\",\"url\":\"https://claude.ai/download\"}],\"sections\":[{\"category\":\"Products\",\"links\":[{\"title\":\"Claude\",\"url\":\"https://claude.com/product/overview\"},{\"title\":\"Claude Code\",\"url\":\"https://claude.com/product/claude-code\"},{\"title\":\"Claude Developer Platform\",\"url\":\"https://claude.com/platform/api\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing\"},{\"title\":\"Contact sales\",\"url\":\"https://claude.com/contact-sales\"}]},{\"category\":\"Models\",\"links\":[{\"title\":\"Opus\",\"url\":\"/claude/opus\"},{\"title\":\"Sonnet\",\"url\":\"/claude/sonnet\"},{\"title\":\"Haiku\",\"url\":\"/claude/haiku\"}]},{\"category\":\"Log in\",\"links\":[{\"title\":\"Claude.ai\",\"url\":\"https://claude.ai\"},{\"title\":\"Claude Console\",\"url\":\"https://platform.claude.com/\"}]}],\"title\":\"Try Claude\",\"url\":\"https://claude.ai/\"},\"copyright\":\"© 2026 Anthropic PBC\",\"footerNavigation\":[{\"_key\":\"716b96b62292\",\"links\":[{\"title\":\"Claude\",\"url\":\"https://claude.com/product/overview\"},{\"title\":\"Claude Code\",\"url\":\"https://claude.com/product/claude-code\"},{\"title\":\"Cowork\",\"url\":\"https://claude.com/product/cowork\"},{\"title\":\"Claude in Chrome\",\"url\":\"https://claude.com/chrome\"},{\"title\":\"Claude in Excel\",\"url\":\"https://claude.com/claude-in-excel\"},{\"title\":\"Claude in PowerPoint\",\"url\":\"https://claude.com/claude-in-powerpoint\"},{\"title\":\"Claude in Slack\",\"url\":\"https://claude.com/claude-in-slack\"},{\"title\":\"Skills\",\"url\":\"https://www.claude.com/skills\"},{\"title\":\"Max plan\",\"url\":\"https://claude.com/pricing/max\"},{\"title\":\"Team plan\",\"url\":\"https://claude.com/pricing/team\"},{\"title\":\"Enterprise plan\",\"url\":\"https://claude.com/pricing/enterprise\"},{\"title\":\"Download app\",\"url\":\"https://claude.ai/download\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing\"},{\"title\":\"Log in to Claude\",\"url\":\"https://claude.ai/\"}],\"title\":\"Products\"},{\"_key\":\"0229138ff25d\",\"links\":[{\"title\":\"Opus\",\"url\":\"/www.anthropic.com/claude/opus\"},{\"title\":\"Sonnet\",\"url\":\"/www.anthropic.com/claude/sonnet\"},{\"title\":\"Haiku\",\"url\":\"/www.anthropic.com/claude/haiku\"}],\"title\":\"Models\"},{\"_key\":\"df2df9219e3abce95d6d83387e2d9bd6\",\"links\":[{\"title\":\"AI agents\",\"url\":\"https://claude.com/solutions/agents\"},{\"title\":\"Code modernization\",\"url\":\"https://claude.com/solutions/code-modernization\"},{\"title\":\"Coding\",\"url\":\"https://claude.com/solutions/coding\"},{\"title\":\"Customer support\",\"url\":\"https://claude.com/solutions/customer-support\"},{\"title\":\"Education\",\"url\":\"https://claude.com/solutions/education\"},{\"title\":\"Financial services\",\"url\":\"https://claude.com/solutions/financial-services\"},{\"title\":\"Government\",\"url\":\"https://claude.com/solutions/government\"},{\"title\":\"Healthcare\",\"url\":\"https://claude.com/solutions/healthcare\"},{\"title\":\"Life sciences\",\"url\":\"https://claude.com/solutions/life-sciences\"},{\"title\":\"Nonprofits\",\"url\":\"https://claude.com/solutions/nonprofits\"}],\"title\":\"Solutions\"},{\"_key\":\"f286ca01fc7aaabd131f347b711a971b\",\"links\":[{\"title\":\"Overview\",\"url\":\"https://claude.com/platform/api\"},{\"title\":\"Developer docs\",\"url\":\"https://platform.claude.com/docs\"},{\"title\":\"Pricing\",\"url\":\"https://claude.com/pricing#api\"},{\"title\":\"Regional compliance\",\"url\":\"https://claude.com/regional-compliance\"},{\"title\":\"Amazon Bedrock\",\"url\":\"https://claude.com/partners/amazon-bedrock\"},{\"title\":\"Google Cloud’s Vertex AI\",\"url\":\"https://claude.com/partners/google-cloud-vertex-ai\"},{\"title\":\"Console login\",\"url\":\"https://platform.claude.com/\"}],\"title\":\"Claude Developer Platform\"},{\"_key\":\"4b255e67f68c270e0072c7564e084e24\",\"links\":[{\"title\":\"Blog\",\"url\":\"https://claude.com/blog\"},{\"title\":\"Claude partner network\",\"url\":\"https://claude.com/partners\"},{\"title\":\"Connectors\",\"url\":\"https://claude.com/connectors\"},{\"title\":\"Courses\",\"url\":\"/learn\"},{\"title\":\"Customer stories\",\"url\":\"https://claude.com/customers\"},{\"title\":\"Engineering at Anthropic\",\"url\":\"/engineering\"},{\"title\":\"Events\",\"url\":\"/events\"},{\"title\":\"Plugins\",\"url\":\"https://claude.com/plugins\"},{\"title\":\"Powered by Claude\",\"url\":\"https://claude.com/partners/powered-by-claude\"},{\"title\":\"Service partners\",\"url\":\"https://claude.com/partners/services\"},{\"title\":\"Startups program\",\"url\":\"https://claude.com/programs/startups\"},{\"title\":\"Tutorials\",\"url\":\"https://claude.com/resources/tutorials\"},{\"title\":\"Use cases\",\"url\":\"https://claude.com/resources/use-cases\"}],\"title\":\"Learn\"},{\"_key\":\"4f2729951e15b0b870897e0444f5f3e1\",\"links\":[{\"title\":\"Anthropic\",\"url\":\"/company\"},{\"title\":\"Careers\",\"url\":\"/careers\"},{\"title\":\"Economic Futures\",\"url\":\"/economic-index\"},{\"title\":\"Research\",\"url\":\"/research\"},{\"title\":\"News\",\"url\":\"/news\"},{\"title\":\"Claude’s Constitution\",\"url\":\"/constitution\"},{\"title\":\"Responsible Scaling Policy\",\"url\":\"/www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy\"},{\"title\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com/\"},{\"title\":\"Transparency\",\"url\":\"/transparency\"}],\"title\":\"Company\"},{\"_key\":\"a886dd1838335844d635f2857b25d66a\",\"links\":[{\"title\":\"Availability\",\"url\":\"/www.anthropic.com/supported-countries\"},{\"title\":\"Status\",\"url\":\"https://status.anthropic.com/\"},{\"title\":\"Support center\",\"url\":\"https://support.claude.com/en/\"}],\"title\":\"Help and security\"},{\"_key\":\"3c3b033c11fa832a35d43b87d55a5364\",\"links\":[{\"title\":\"Privacy choices\",\"url\":\"#\"},{\"title\":\"Privacy policy\",\"url\":\"/www.anthropic.com/legal/privacy\"},{\"title\":\"Consumer health data privacy policy\",\"url\":\"/www.anthropic.com/legal/consumer-health-data-privacy-policy\"},{\"title\":\"Responsible disclosure policy\",\"url\":\"/www.anthropic.com/responsible-disclosure-policy\"},{\"title\":\"Terms of service: Commercial\",\"url\":\"/www.anthropic.com/legal/commercial-terms\"},{\"title\":\"Terms of service: Consumer\",\"url\":\"/www.anthropic.com/legal/consumer-terms\"},{\"title\":\"Usage policy\",\"url\":\"/www.anthropic.com/legal/aup\"}],\"title\":\"Terms and policies\"}],\"headerNavigation\":[{\"_key\":\"a340f9d4b859\",\"category\":\"Research\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/research\"},{\"_key\":\"a483c7dfd38a\",\"category\":\"Economic Futures\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/economic-futures\"},{\"_key\":\"82c471bd311d\",\"category\":\"Commitments\",\"displayType\":\"sections\",\"sections\":[{\"_key\":\"675871636e4d\",\"links\":[{\"title\":\"Claude’s Constitution\",\"url\":\"/constitution\"},{\"title\":\" Transparency\",\"url\":\"/transparency\"},{\"title\":\"Responsible Scaling Policy\",\"url\":\"/news/announcing-our-updated-responsible-scaling-policy\"}],\"title\":\"Initiatives\"},{\"_key\":\"16af50a6e2dd\",\"links\":[{\"title\":\"Security and compliance\",\"url\":\"https://trust.anthropic.com/\"}],\"title\":\"Trust center\"}]},{\"_key\":\"861a11ed9931\",\"category\":\"Learn\",\"displayType\":\"sections\",\"sections\":[{\"_key\":\"9f9f720a8793\",\"links\":[{\"title\":\"Anthropic Academy\",\"url\":\"/learn\"},{\"title\":\"Tutorials\",\"url\":\"https://claude.com/resources/tutorials\"},{\"title\":\"Use cases\",\"url\":\"https://claude.com/resources/use-cases\"},{\"title\":\"Engineering at Anthropic\",\"url\":\"/engineering\"},{\"title\":\"Developer docs\",\"url\":\"https://docs.claude.com\"}],\"title\":\"Learn\"},{\"_key\":\"6bd061c46b10\",\"links\":[{\"title\":\"About\",\"url\":\"/company\"},{\"title\":\"Careers\",\"url\":\"/careers\"},{\"title\":\"Events\",\"url\":\"/events\"}],\"title\":\"Company\"}]},{\"_key\":\"22e8d8d2923d\",\"category\":\"News\",\"displayType\":\"singleLink\",\"sections\":null,\"url\":\"/news\"}],\"internalName\":\"anthropic.com Site Settings\",\"linkedInUsername\":\"anthropicresearch\",\"meta\":{\"_createdAt\":\"2023-11-20T21:56:31Z\",\"_id\":\"0f6290ad-6d21-407d-8deb-ce02815d1383\",\"_rev\":\"NyW74GU9ZzyWgAYa8qUSlF\",\"_type\":\"metadata\",\"_updatedAt\":\"2023-11-20T23:54:09Z\",\"robotsIndexable\":true,\"seoDescription\":\"Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems.\",\"seoTitle\":\"Anthropic\",\"socialImage\":{\"_type\":\"image\",\"asset\":{\"_createdAt\":\"2025-05-23T14:14:18Z\",\"_id\":\"image-c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260-jpg\",\"_rev\":\"v1N2wBpLqoO2Q3HXueYiJi\",\"_type\":\"sanity.imageAsset\",\"_updatedAt\":\"2025-05-23T14:14:18Z\",\"assetId\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"extension\":\"jpg\",\"metadata\":{\"_type\":\"sanity.imageMetadata\",\"blurHash\":\"MASPU,%M?b%Ms:-;j[j[j[fQ~qj[9FayWB\",\"dimensions\":{\"_type\":\"sanity.imageDimensions\",\"aspectRatio\":1.9047619047619047,\"height\":1260,\"width\":2400},\"hasAlpha\":false,\"isOpaque\":true,\"lqip\":\"data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAKABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAQFCP/EACAQAAEEAgEFAAAAAAAAAAAAAAABAgMEBRETEhQhIjH/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwDS96axCjO2r8yqvn21oiR3ci6TT8d0t395ELUGVAAB/9k=\",\"palette\":{\"_type\":\"sanity.imagePalette\",\"darkMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#444440\",\"foreground\":\"#fff\",\"population\":0.05,\"title\":\"#fff\"},\"darkVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#68681c\",\"foreground\":\"#fff\",\"population\":0,\"title\":\"#fff\"},\"dominant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"lightMuted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#bcbcb4\",\"foreground\":\"#000\",\"population\":0.03,\"title\":\"#fff\"},\"lightVibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#fcfcf4\",\"foreground\":\"#000\",\"population\":90.85,\"title\":\"#000\"},\"muted\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#7c7c74\",\"foreground\":\"#fff\",\"population\":0.02,\"title\":\"#fff\"},\"vibrant\":{\"_type\":\"sanity.imagePaletteSwatch\",\"background\":\"#c8c836\",\"foreground\":\"#000\",\"population\":0,\"title\":\"#fff\"}}},\"mimeType\":\"image/jpeg\",\"originalFilename\":\"Anthropic-OG-image.jpg\",\"path\":\"images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\",\"sha1hash\":\"c07f638082c569e8ce1e89ae95ee6f332a98ec08\",\"size\":132598,\"uploadId\":\"pxmJEaCvYm0cHoZTfnCcZYXxrWKBhHf0\",\"url\":\"https://cdn.sanity.io/images/4zrzovbb/website/c07f638082c569e8ce1e89ae95ee6f332a98ec08-2400x1260.jpg\"},\"description\":\"Anthropic logo\"}},\"siteName\":\"Anthropic\",\"sitemapUrls\":[\"/\",\"/careers\",\"/company\",\"/events\",\"/events/aws-summit-dc\",\"/events/aws-summit-nyc\",\"/events/aws-summit-london\",\"/events/aws-summit-tokyo\",\"/events/claude-for-finance\",\"/events/google-cloud-next-2025\",\"/events/paris-builder-summit\",\"/events/seoul-builder-summit\",\"/learn\",\"/supported-countries\",\"/unsubscribe\"],\"twitterUsername\":\"AnthropicAI\",\"youtubeUsername\":\"anthropic-ai\",\"hideFooter\":true},\"page\":{\"_type\":\"page\",\"_id\":\"not-found\",\"_rev\":\"\",\"_createdAt\":\"\",\"_updatedAt\":\"\",\"title\":\"Not Found\",\"slug\":{\"_type\":\"slug\",\"current\":\"not-found\"},\"meta\":{},\"sections\":[]},\"theme\":\"$undefined\"}],\"$L19\",null]}]\n"])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"19:[\"$\",\"main\",null,{\"id\":\"main-content\",\"className\":\"\",\"children\":[\"$\",\"$L1a\",null,{}]}]\n"])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"11:[[\"$\",\"title\",\"0\",{\"children\":\"Contextual Retrieval in AI Systems \\\\ Anthropic\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Explore how Anthropic enhances AI systems through advanced contextual retrieval methods. Learn about our approach to improving information access and relevance in large language models.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"msapplication-TileColor\",\"content\":\"141413\"}],[\"$\",\"meta\",\"3\",{\"name\":\"msapplication-config\",\"content\":\"/browserconfig.xml\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:title\",\"content\":\"Contextual Retrieval in AI Systems\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:description\",\"content\":\"Explore how Anthropic enhances AI systems through advanced contextual retrieval methods. Learn about our approach to improving information access and relevance in large language models.\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:image\",\"content\":\"https://cdn.sanity.io/images/4zrzovbb/website/2bb957622142f53575f476f76473593fa89d1dc8-2400x1260.png\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:image:alt\",\"content\":\"Anthropic logo\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"10\",{\"name\":\"twitter:site\",\"content\":\"@AnthropicAI\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:creator\",\"content\":\"@AnthropicAI\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"Contextual Retrieval in AI Systems\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"Explore how Anthropic enhances AI systems through advanced contextual retrieval methods. Learn about our approach to improving information access and relevance in large language models.\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:image\",\"content\":\"https://cdn.sanity.io/images/4zrzovbb/website/2bb957622142f53575f476f76473593fa89d1dc8-2400x1260.png\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:image:alt\",\"content\":\"Anthropic logo\"}],[\"$\",\"link\",\"16\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"link\",\"17\",{\"rel\":\"icon\",\"href\":\"/images/icons/favicon-32x32.png\"}],[\"$\",\"link\",\"18\",{\"rel\":\"apple-touch-icon\",\"href\":\"/images/icons/apple-touch-icon.png\"}],[\"$\",\"link\",\"19\",{\"rel\":\"apple-touch-icon\",\"href\":\"/images/icons/apple-touch-icon.png\",\"sizes\":\"180x180\"}],[\"$\",\"link\",\"20\",{\"rel\":\"mask-icon\",\"href\":\"/images/icons/safari-pinned-tab.svg\",\"color\":\"141413\"}],[\"$\",\"$L1b\",\"21\",{}]]\n"])</script><script nonce="Y2ZjNWYxNTYtNjEwNC00MTk1LWIwNTUtMmVmZjlkYjljMzMz">self.__next_f.push([1,"d:null\n"])</script></body></html>